{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76f6f215-269b-4ada-bf48-5ba0f3231e2c",
   "metadata": {},
   "source": [
    "# Quickstart for creating a Vertex Vector Search Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd6ff27-e3ce-47cb-931b-66827016fddb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1bef88-760d-4cc6-9ec4-5115dd8a6254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud services enable compute.googleapis.com \\\n",
    "#                         aiplatform.googleapis.com \\\n",
    "#                         storage.googleapis.com \\\n",
    "#                         iam.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51486dd3-b9fd-4747-b67d-8fd66bc9e161",
   "metadata": {},
   "source": [
    "### pip installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f47fd1ec-78a3-4d39-9997-9079b0beefe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade --user google-cloud-aiplatform google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f20d33c-3458-4473-ae5e-e00e25183573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "# import time\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78076478-d69e-4816-be0a-34c0cc59838a",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aa350be-d6db-4dd1-bc33-8213184a2cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform_v1 as aipv1\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "#python warning \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50eb5bb5-116e-43d1-8f51-86aede5a1405",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery SDK version      : 3.15.0\n",
      "Vertex AI SDK version     : 1.39.0\n",
      "Cloud Storage SDK version : 2.14.0\n"
     ]
    }
   ],
   "source": [
    "print(f'BigQuery SDK version      : {bigquery.__version__}')\n",
    "print(f'Vertex AI SDK version     : {aiplatform.__version__}')\n",
    "print(f'Cloud Storage SDK version : {storage.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14ace3c-fc05-4d88-89c2-228c2865df4b",
   "metadata": {},
   "source": [
    "### Define vars and GCP env config\n",
    "\n",
    "`CREATE_NEW_ASSETS`\n",
    "* True creates new GCS buckets and Vector Search instances, etc.\n",
    "* False skips these steps (in case you need to re-run notebook to include new variables you create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ef3881a-e0b2-4f91-9036-01a66a39507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new gcs bucket, vs index, etc.?\n",
    "CREATE_NEW_ASSETS         = True "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae8e5bf-364d-49b1-bc48-6725b9cbfaab",
   "metadata": {},
   "source": [
    "**Edit these to define naming conventions and stay organized across different versions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28730dbe-9bca-4b7d-8e09-ca779522066d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX = vvs-vectorio-pubv2\n"
     ]
    }
   ],
   "source": [
    "# naming convention for all cloud resources\n",
    "VERSION        = \"pubv2\"                     # TODO\n",
    "PREFIX         = f'vvs-vectorio-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX = {PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7973084-b8cd-433f-96ba-a5728684de60",
   "metadata": {},
   "source": [
    "#### Edit these as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaad187e-e6ef-43a9-89aa-bb525a206462",
   "metadata": {},
   "source": [
    "`VPC_NETWORK_NAME`\n",
    "* if index will be **deployed to a private endpoint** within a VPC network, edit this with the name of your VPC network name\n",
    "* if index will be **deployed to a public endpoint**, leave blank\n",
    "\n",
    "> For details on configuring VPC for Vertex AI Vector Search, see **[Set up a VPC Network Peering connection](https://cloud.google.com/vertex-ai/docs/vector-search/setup/vpc)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef68899-8494-411f-901b-a693ed0a22c0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>⚠️ if deploying index to index endpoint within a VPC network, you must interact with the index endpoint from within the VPC network, i.e., run this notebook in a Vertex Workbench instance within that VPC ⚠️</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de35ef8e-e64a-451b-a963-1cc8b74fdb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VPC_NETWORK_NAME = \"\"  # e.g., \"your-vpc-name\" | \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dd8575e-13ee-4094-af90-067f05f59ac5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VPC_NETWORK_NAME     = \n",
      "USE_PUBLIC_ENDPOINTS = True\n"
     ]
    }
   ],
   "source": [
    "if VPC_NETWORK_NAME:\n",
    "    USE_PUBLIC_ENDPOINTS = False\n",
    "else:\n",
    "    USE_PUBLIC_ENDPOINTS = True\n",
    "    \n",
    "print(f\"VPC_NETWORK_NAME     = {VPC_NETWORK_NAME}\")\n",
    "print(f\"USE_PUBLIC_ENDPOINTS = {USE_PUBLIC_ENDPOINTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e408fff-cf90-4156-a6ac-ac59d04e2667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGION    = us-central1\n",
      "BQ_REGION = US\n"
     ]
    }
   ],
   "source": [
    "# locations / regions for cloud resources\n",
    "REGION            = 'us-central1'        \n",
    "BQ_REGION         = 'US'\n",
    "\n",
    "print(f\"REGION    = {REGION}\")\n",
    "print(f\"BQ_REGION = {BQ_REGION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd4018f-f261-4d64-b851-d57861933ba1",
   "metadata": {},
   "source": [
    "#### Let these ride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65f4133a-3677-4352-b223-3c6794d02de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID       = hybrid-vertex\n",
      "PROJECT_NUM      = 934903580331\n",
      "VERTEX_SA        = 934903580331-compute@developer.gserviceaccount.com\n",
      "VPC_NETWORK_FULL = projects/934903580331/global/networks/\n",
      "BUCKET_NAME      = vvs-vectorio-pubv2-hybrid-vertex\n",
      "BUCKET_URI       = gs://vvs-vectorio-pubv2-hybrid-vertex\n"
     ]
    }
   ],
   "source": [
    "# let these ride\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "PROJECT_NUM              = !gcloud projects describe $PROJECT_ID --format=\"value(projectNumber)\"\n",
    "PROJECT_NUM              = PROJECT_NUM[0]\n",
    "\n",
    "# service account\n",
    "VERTEX_SA                = f'{PROJECT_NUM}-compute@developer.gserviceaccount.com'\n",
    "\n",
    "# full VPC network name\n",
    "VPC_NETWORK_FULL         = f\"projects/{PROJECT_NUM}/global/networks/{VPC_NETWORK_NAME}\"\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "print(f\"PROJECT_ID       = {PROJECT_ID}\")\n",
    "print(f\"PROJECT_NUM      = {PROJECT_NUM}\")\n",
    "print(f\"VERTEX_SA        = {VERTEX_SA}\")\n",
    "print(f\"VPC_NETWORK_FULL = {VPC_NETWORK_FULL}\")\n",
    "print(f\"BUCKET_NAME      = {BUCKET_NAME}\")\n",
    "print(f\"BUCKET_URI       = {BUCKET_URI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f30dea40-40ea-466e-a1ce-ee8057619165",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0c55a7-c42e-4b4e-90c8-88ca006e561e",
   "metadata": {},
   "source": [
    "### Create GCS bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56b2944b-e2e3-422a-9752-9810b83b6d37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://vvs-vectorio-pubv2-hybrid-vertex/...\n",
      "934903580331-compute@developer.gserviceaccount.com should have access to gs://vvs-vectorio-pubv2-hybrid-vertex\n"
     ]
    }
   ],
   "source": [
    "if CREATE_NEW_ASSETS:\n",
    "    \n",
    "    # create new bucket\n",
    "    ! gsutil mb -l $REGION $BUCKET_URI\n",
    "    \n",
    "    # ### give Service account Admin to GCS\n",
    "    # !gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "    #     --member=serviceAccount:$VERTEX_SA \\\n",
    "    #     --role=roles/storage.admin\n",
    "    \n",
    "    ### uncomment if org policy prevents granting Admin:\n",
    "    # ! gsutil iam ch serviceAccount:{$VERTEX_SA}:roles/storage.objects.get $BUCKET_URI\n",
    "    # ! gsutil iam ch serviceAccount:{$VERTEX_SA}:roles/storage.objects.create $BUCKET_URI\n",
    "    # ! gsutil iam ch serviceAccount:{$VERTEX_SA}:roles/storage.objects.list $BUCKET_URI\n",
    "    \n",
    "    \n",
    "print(f\"{VERTEX_SA} should have access to {BUCKET_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde75602-121f-4ce1-a416-34d810d32383",
   "metadata": {},
   "source": [
    "### Save notebook config \n",
    "\n",
    "> to easily use in other GCP related notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ce416aa-7d10-4ac0-94ba-44b0fcb87571",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PREFIX                   = \"vvs-vectorio-pubv2\"\n",
      "VERSION                  = \"pubv2\"\n",
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_REGION                = \"US\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "VPC_NETWORK_NAME         = \"\"\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/\"\n",
      "\n",
      "USE_PUBLIC_ENDPOINTS     = \"True\"\n",
      "\n",
      "BUCKET_NAME              = \"vvs-vectorio-pubv2-hybrid-vertex\"\n",
      "BUCKET_URI               = \"gs://vvs-vectorio-pubv2-hybrid-vertex\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = f\"\"\"\n",
    "PREFIX                   = \\\"{PREFIX}\\\"\n",
    "VERSION                  = \\\"{VERSION}\\\"\n",
    "\n",
    "PROJECT_ID               = \\\"{PROJECT_ID}\\\"\n",
    "PROJECT_NUM              = \\\"{PROJECT_NUM}\\\"\n",
    "\n",
    "REGION                   = \\\"{REGION}\\\"\n",
    "BQ_REGION                = \\\"{BQ_REGION}\\\"\n",
    "\n",
    "VERTEX_SA                = \\\"{VERTEX_SA}\\\"\n",
    "\n",
    "VPC_NETWORK_NAME         = \\\"{VPC_NETWORK_NAME}\\\"\n",
    "VPC_NETWORK_FULL         = \\\"{VPC_NETWORK_FULL}\\\"\n",
    "\n",
    "USE_PUBLIC_ENDPOINTS     = \\\"{USE_PUBLIC_ENDPOINTS}\\\"\n",
    "\n",
    "BUCKET_NAME              = \\\"{BUCKET_NAME}\\\"\n",
    "BUCKET_URI               = \\\"{BUCKET_URI}\\\"\n",
    "\"\"\"\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d54aa565-eebd-4b6d-8008-21a6c2c369dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying from <STDIN>...\n",
      "/ [1 files][    0.0 B/    0.0 B]                                                \n",
      "Operation completed over 1 objects.                                              \n"
     ]
    }
   ],
   "source": [
    "!echo '{config}' | gsutil cp - {BUCKET_URI}/config/notebook_env.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3828350-76f1-4a22-b331-39867c9c8431",
   "metadata": {},
   "source": [
    "### Initialize Google Cloud SDK Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93b65a4c-4b73-47d2-b488-3ca64242cad2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "# bigquery client\n",
    "bq_client = bigquery.Client(\n",
    "    project=PROJECT_ID,\n",
    "    # location=BQ_REGION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148e8a43-a4e2-4967-9f16-54e0aff92e38",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare StackOverflow data\n",
    "You use the [Stack Overflow dataset](https://console.cloud.google.com/marketplace/product/stack-exchange/stack-overflow) of question and answers hosted on BigQuery.\n",
    "\n",
    "> This public dataset is hosted in Google BigQuery and is included in BigQuery's 1TB/mo of free tier processing. This means that each user receives 1TB of free BigQuery processing every month, which can be used to run queries on this public dataset.\n",
    "\n",
    "The BigQuery table is too large to fit into memory, so you need to write a generator called `query_bigquery_chunks` to yield chunks of the dataframe for processing. Additionally, an extra column `title_with_body` is added, which is a concatenation of the question title and body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f229757d-9c13-4d3b-8603-d154f28c9a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Any, Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7112765e-01b3-45a1-abd3-8615220ce23a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "QUERY_TEMPLATE = \"\"\"\n",
    "        SELECT DISTINCT q.id, \n",
    "           q.title, \n",
    "           q.body, \n",
    "           q.score, \n",
    "           q.tags,\n",
    "        FROM (\n",
    "            SELECT * FROM `bigquery-public-data.stackoverflow.posts_questions` \n",
    "            WHERE score > 0 \n",
    "            ORDER BY view_count DESC\n",
    "            ) AS q \n",
    "        LIMIT {limit} OFFSET {offset};\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "def query_bigquery_chunks(\n",
    "    max_rows: int, \n",
    "    rows_per_chunk: int, \n",
    "    start_chunk: int = 0\n",
    ") -> Generator[pd.DataFrame, Any, None]:\n",
    "    \n",
    "    for offset in range(start_chunk, max_rows, rows_per_chunk):\n",
    "        query = QUERY_TEMPLATE.format(limit=rows_per_chunk, offset=offset)\n",
    "        query_job = bq_client.query(query)\n",
    "        rows = query_job.result()\n",
    "        df = rows.to_dataframe()\n",
    "        df[\"title_with_body\"] = df.title + \"\\n\" + df.body\n",
    "        df['tags_split_1'] = df['tags'].apply(lambda x: x.split('|', maxsplit=1)[0])\n",
    "        df['tags_split_2'] = df['tags'].apply(lambda x: x.split('|', maxsplit=1)[0])\n",
    "        df.drop(columns=[\"body\",\"tags\"], inplace=True)\n",
    "        yield df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b7f536e-de44-4f49-9e6a-c67ef627369a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (100, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>title_with_body</th>\n",
       "      <th>tags_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54839558</td>\n",
       "      <td>Call JS onsubmit only when form is valid</td>\n",
       "      <td>1</td>\n",
       "      <td>Call JS onsubmit only when form is valid\\n&lt;p&gt;I...</td>\n",
       "      <td>javascript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54736309</td>\n",
       "      <td>How to use output for one function as paramete...</td>\n",
       "      <td>1</td>\n",
       "      <td>How to use output for one function as paramete...</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54991610</td>\n",
       "      <td>How to look up previous values in an R data fr...</td>\n",
       "      <td>1</td>\n",
       "      <td>How to look up previous values in an R data fr...</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55018619</td>\n",
       "      <td>Adding Firebase Crashlytics either crash in ru...</td>\n",
       "      <td>6</td>\n",
       "      <td>Adding Firebase Crashlytics either crash in ru...</td>\n",
       "      <td>android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54813658</td>\n",
       "      <td>Shopify create user activation email</td>\n",
       "      <td>1</td>\n",
       "      <td>Shopify create user activation email\\n&lt;p&gt;How c...</td>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  score  \\\n",
       "0  54839558           Call JS onsubmit only when form is valid      1   \n",
       "1  54736309  How to use output for one function as paramete...      1   \n",
       "2  54991610  How to look up previous values in an R data fr...      1   \n",
       "3  55018619  Adding Firebase Crashlytics either crash in ru...      6   \n",
       "4  54813658               Shopify create user activation email      1   \n",
       "\n",
       "                                     title_with_body  tags_split  \n",
       "0  Call JS onsubmit only when form is valid\\n<p>I...  javascript  \n",
       "1  How to use output for one function as paramete...      python  \n",
       "2  How to look up previous values in an R data fr...           r  \n",
       "3  Adding Firebase Crashlytics either crash in ru...     android  \n",
       "4  Shopify create user activation email\\n<p>How c...          c#  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a dataframe of 1000 rows for demonstration purposes\n",
    "df_test = next(\n",
    "    query_bigquery_chunks(\n",
    "        max_rows=500, \n",
    "        rows_per_chunk=100,\n",
    "        start_chunk=0\n",
    "    )\n",
    ")\n",
    "\n",
    "# Examine the data\n",
    "print(f\"df shape: {df_test.shape}\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98e0436-3cc7-48cf-9280-5a58fd2ef87c",
   "metadata": {},
   "source": [
    "## Instantiate the text encoding model\n",
    "\n",
    "> Use the [Vertex AI Embeddings for Text API](https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings) developed by Google for converting text to embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e7c9e1-3fb1-44c0-b466-82bb7a97ab97",
   "metadata": {},
   "source": [
    "### Define helper functions\n",
    "\n",
    "* `encode_texts_to_embeddings()`: convert sentences to embeddings\n",
    "\n",
    "* `generate_batches()`: splits sentences into batches of 5 before sending to the embedding API\n",
    "\n",
    "* `encode_text_to_embedding_batched()`: calls `generate_batches()` to handle batching, calls embedding API via `encode_texts_to_embeddings()`, handles rate-limiting using `time.sleep` *(Note: For production use cases, use more sophisticated rate-limiting mechanism that takes retries into account)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "900099e4-ac26-4b3a-8fda-22491b01235c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0413818a-09a0-4114-b94c-df2ee104779c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "# Load the \"Vertex AI Embeddings for Text\" model\n",
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "\n",
    "model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\n",
    "\n",
    "\n",
    "# Define an embedding method that uses the model\n",
    "def encode_texts_to_embeddings(sentences: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        embeddings = model.get_embeddings(sentences)\n",
    "        return [embedding.values for embedding in embeddings]\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(sentences))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dc5c3a9-29ee-45af-88ba-b01df08a93d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Generator, List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# Generator function to yield batches of sentences\n",
    "def generate_batches(\n",
    "    sentences: List[str], \n",
    "    batch_size: int\n",
    ") -> Generator[List[str], None, None]:\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        yield sentences[i : i + batch_size]\n",
    "\n",
    "\n",
    "def encode_text_to_embedding_batched(\n",
    "    sentences: List[str], \n",
    "    api_calls_per_second: int = 10, \n",
    "    batch_size: int = 5\n",
    ") -> Tuple[List[bool], np.ndarray]:\n",
    "\n",
    "    embeddings_list: List[List[float]] = []\n",
    "\n",
    "    # Prepare the batches using a generator\n",
    "    batches = generate_batches(sentences, batch_size)\n",
    "\n",
    "    seconds_per_job = 1 / api_calls_per_second\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for batch in tqdm(\n",
    "            batches, total=math.ceil(len(sentences) / batch_size), position=0\n",
    "        ):\n",
    "            futures.append(\n",
    "                executor.submit(functools.partial(encode_texts_to_embeddings), batch)\n",
    "            )\n",
    "            time.sleep(seconds_per_job)\n",
    "\n",
    "        for future in futures:\n",
    "            embeddings_list.extend(future.result())\n",
    "\n",
    "    is_successful = [\n",
    "        embedding is not None for sentence, embedding in zip(sentences, embeddings_list)\n",
    "    ]\n",
    "    embeddings_list_successful = np.squeeze(\n",
    "        np.stack([embedding for embedding in embeddings_list if embedding is not None])\n",
    "    )\n",
    "    return is_successful, embeddings_list_successful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffddc20-68b0-454a-a7cd-81b3a27be57f",
   "metadata": {},
   "source": [
    "*test encoding function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9508a3b8-456e-47e5-b049-9840e8a97244",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e0626fc9c14812a94cabe29e9f6ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encode a subset of questions for validation\n",
    "questions = df_test.title.tolist()[:500]\n",
    "\n",
    "is_successful, question_embeddings = encode_text_to_embedding_batched(\n",
    "    sentences=df_test.title.tolist()[:500],\n",
    ")\n",
    "\n",
    "# Filter for successfully embedded sentences\n",
    "questions = np.array(questions)[is_successful]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33957031-69c2-4248-a6d2-f44c348eeec9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Call JS onsubmit only when form is valid'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(questions.shape)\n",
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f10b7dca-3a2e-4885-826f-9c55bb5619c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 768)\n"
     ]
    }
   ],
   "source": [
    "print(question_embeddings.shape)\n",
    "# question_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e927ceee-5aba-4bf2-81d5-966f57109d11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(is_successful)\n",
    "is_successful[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32e0fe28-c865-4e5c-8e8f-af24490d59f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "DIMENSIONS = len(question_embeddings[0])\n",
    "\n",
    "print(DIMENSIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c551d0d6-57cb-4d0e-a118-a483ca52b6a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query question = How to look up previous values in an R data frame by ID and year?\n",
      "\t0: How to look up previous values in an R data frame by ID and year?: 0.9999994333182649\n",
      "\t1: Needing YTD Data from SQL: 0.6629148880643077\n",
      "\t2: Multiple Regression - Error in model.frame.default variable lengths differ: 0.6301273325358208\n",
      "\t3: How to add Standard error to a nls plot using ggplot2?: 0.6184790667532307\n",
      "\t4: SQL QUERY : multiple records against one column value . need to compare another column value to fetch one record: 0.5868768786140578\n",
      "\t5: overwrite data in google sheet using python: 0.5858167421303139\n",
      "\t6: How to cache subquery result in WITH clause in Spark SQL: 0.5764415522845228\n",
      "\t7: How to hide repetitive data while retrieving data from database: 0.5739066996016109\n",
      "\t8: How to use output for one function as parameter for another: 0.5704656084304427\n",
      "\t9: How to combine Images of different channel?: 0.5640245568680563\n",
      "\t10: How to use threading with selenium for web scraping?: 0.5565841395721643\n",
      "\t11: When is new Gmail API History ID generated: 0.5520593437948975\n",
      "\t12: Extracting the number of value occurrences from a nested dictionary: 0.5505853051846328\n",
      "\t13: Last iteration on For loop with If condition with twig: 0.5436270298288542\n",
      "\t14: Google Sheets Query returning results that don't exist in the source list: 0.5399312255082327\n",
      "\t15: How do I move the VALUE in a register to a memory variable in NASM?: 0.5358044292174989\n",
      "\t16: ffmpeg motion interpolation for 2x and 4x slowmotion: 0.5311048531693314\n",
      "\t17: How to define entities with intent independent in RASA NLU?: 0.529758008659801\n",
      "\t18: Variable can be of two different types: 0.528771948919048\n",
      "\t19: iopl() fails intermittently: 0.5254030926018132\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "question_index = random.randint(0, 99)\n",
    "\n",
    "print(f\"Query question = {questions[question_index]}\")\n",
    "\n",
    "# Get similarity scores for each embedding by using dot-product.\n",
    "scores = np.dot(question_embeddings[question_index], question_embeddings.T)\n",
    "\n",
    "# Print top 20 matches\n",
    "for index, (question, score) in enumerate(\n",
    "    sorted(zip(questions, scores), key=lambda x: x[1], reverse=True)[:20]\n",
    "):\n",
    "    print(f\"\\t{index}: {question}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1c1a4b1-afbb-4312-a4fd-4403ece2c42b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings directory: /var/tmp/tmp7wy_c7yy\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Create temporary file to write embeddings to\n",
    "embeddings_file_path = Path(tempfile.mkdtemp())\n",
    "\n",
    "print(f\"Embeddings directory: {embeddings_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc756d91-0d45-4cb8-b0c4-008bb6642b7a",
   "metadata": {},
   "source": [
    "### formatting vectors for Vertex Vector Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edd582f-a176-4118-af81-9b9886c9eb57",
   "metadata": {},
   "source": [
    "**embedding_vector**\n",
    "* Encode the file using UTF-8.\n",
    "* Make each line a valid `.json` object to be interpreted as a record.\n",
    "* Include in each record a field named `id` that requires a valid UTF-8 string that is the ID of the vector.\n",
    "* Include in each record a field named embedding that requires an array of numbers. This is the feature vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00273b6-6cba-4fff-a990-df3fbff106ab",
   "metadata": {},
   "source": [
    "Filtering with **String Namespaces**\n",
    "\n",
    "The value of the field `restricts`, if present, should be an array of objects, each is turned into a TokenNamespace in restricts.\n",
    "\n",
    "For each vector's record, add a field called restricts, to contain an array of objects, each of which is a namespace.\n",
    "\n",
    "* Each object must have a field named namespace. This field is the TokenNamespace.namespace, namespace.\n",
    "* The value of the field allow, if present, is an array of strings. This array of strings is the TokenNamespace.string_tokens list.\n",
    "* The value of the field deny, if present, is an array of strings. This array of strings is the TokenNamespace.string_denylist_tokens list.\n",
    "\n",
    "```\n",
    "{\n",
    "    \"id\": \"42\", \n",
    "    \"embedding\": [0.5, 1.0], \n",
    "    \"restricts\": [\n",
    "        {\"namespace\": \"class\",\"allow\": [\"cat\", \"pet\"]},\n",
    "        {\"namespace\": \"category\", \"allow\": [\"feline\"]}\n",
    "    ]\n",
    "}\n",
    "{\n",
    "    \"id\": \"43\", \n",
    "    \"embedding\": [0.6, 1.0], \n",
    "    \"restricts\": [\n",
    "        {\"namespace\": \"class\", \"allow\": [\"dog\", \"pet\"]},\n",
    "        {\"namespace\": \"category\", \"allow\": [\"canine\"]}\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a882c77b-0c45-4944-84f7-cff5199a1a85",
   "metadata": {},
   "source": [
    "Filtering with **Numeric namespaces**\n",
    "For each vector's record, add a field called `numeric_restricts`, to contain an array of objects, each of which is a numeric restrict.\n",
    "\n",
    "* Each object must have a field named namespace. This field is the NumericRestrictNamespace.namespace, namespace.\n",
    "* Each object must have one of `value_int`, `value_float`, and `value_double`.\n",
    "* Each object must not have a field named op. This field is only for query.\n",
    "\n",
    "```\n",
    "{\n",
    "    \"id\": \"42\", \n",
    "    \"embedding\": [0.5, 1.0], \n",
    "    \"numeric_restricts\": [\n",
    "        {\"namespace\": \"size\", \"value_int\": 3},\n",
    "        {\"namespace\": \"ratio\", \"value_float\": 0.1}\n",
    "    ]\n",
    "}\n",
    "{\n",
    "    \"id\": \"43\", \n",
    "    \"embedding\": [0.6, 1.0], \n",
    "    \"numeric_restricts\": [\n",
    "        {\"namespace\":\"weight\", \"value_double\": 0.3}\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a26ba3-62b6-4d34-b6d5-c17c668e5f4d",
   "metadata": {},
   "source": [
    "**crowding tag**\n",
    "\n",
    "The value of the field `crowding_tag`, if present, should be a string\n",
    "\n",
    "```\n",
    "{\n",
    "    \"id\": \"43\", \n",
    "    \"embedding\": [0.6, 1.0], \n",
    "    \"numeric_restricts\": [\n",
    "        {\"namespace\":\"weight\", \"value_double\": 0.3}\n",
    "    ],\n",
    "    \"crowding_tag\": \"shoes\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8038bd7a-6feb-4c93-8078-b1453abe0bab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(len(question_embeddings))\n",
    "# question_embeddings[0]\n",
    "\n",
    "# df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "631dc39c-7926-4076-8127-d53b45e81784",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BQ_NUM_ROWS          : 100\n",
      "BQ_CHUNK_SIZE        : 100\n",
      "BQ_NUM_CHUNKS        : 1\n",
      "API_CALLS_PER_SECOND : 5.0\n",
      "ITEMS_PER_REQUEST    : 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469988c34ff9434ea4b488463571f864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Chunk of rows from BigQuery:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: 0 of 1 loops\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879860f2ddb241949fb41e2a24db39ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "import json\n",
    "\n",
    "BQ_NUM_ROWS = 100\n",
    "BQ_CHUNK_SIZE = 100\n",
    "BQ_NUM_CHUNKS = math.ceil(BQ_NUM_ROWS / BQ_CHUNK_SIZE)\n",
    "\n",
    "START_CHUNK = 0\n",
    "\n",
    "# Create a rate limit of 300 requests per minute. Adjust this depending on your quota.\n",
    "API_CALLS_PER_SECOND = 300 / 60\n",
    "# According to the docs, each request can process 5 instances per request\n",
    "ITEMS_PER_REQUEST = 5\n",
    "\n",
    "print(f\"BQ_NUM_ROWS          : {BQ_NUM_ROWS}\")\n",
    "print(f\"BQ_CHUNK_SIZE        : {BQ_CHUNK_SIZE}\")\n",
    "print(f\"BQ_NUM_CHUNKS        : {BQ_NUM_CHUNKS}\")\n",
    "print(f\"API_CALLS_PER_SECOND : {API_CALLS_PER_SECOND}\")\n",
    "print(f\"ITEMS_PER_REQUEST    : {ITEMS_PER_REQUEST}\")\n",
    "\n",
    "\n",
    "# Loop through each generated dataframe, convert\n",
    "for i, df in tqdm(\n",
    "    enumerate(\n",
    "        query_bigquery_chunks(\n",
    "            max_rows=BQ_NUM_ROWS, \n",
    "            rows_per_chunk=BQ_CHUNK_SIZE, \n",
    "            start_chunk=START_CHUNK\n",
    "        )\n",
    "    ),\n",
    "    total=BQ_NUM_CHUNKS - START_CHUNK,\n",
    "    position=-1,\n",
    "    desc=\"Chunk of rows from BigQuery\",\n",
    "):\n",
    "    print(f\"Starting: {i} of {BQ_NUM_CHUNKS} loops\")\n",
    "    \n",
    "    # Create a unique output file for each chunk\n",
    "    chunk_path = embeddings_file_path.joinpath(\n",
    "        f\"{embeddings_file_path.stem}_{i+START_CHUNK}.json\"\n",
    "    )\n",
    "    with open(chunk_path, \"a\") as f:\n",
    "        id_chunk = df.id\n",
    "        scores_chunk = df.score\n",
    "        tags_restrict = df.tags_split_1\n",
    "        tags_crowd = df.tags_split_2\n",
    "\n",
    "        # Convert batch to embeddings\n",
    "        is_successful, question_chunk_embeddings = encode_text_to_embedding_batched(\n",
    "            # sentences=df.title_with_body,\n",
    "            sentences=df.title_with_body.tolist(), #[:500]\n",
    "            api_calls_per_second=API_CALLS_PER_SECOND,\n",
    "            batch_size=ITEMS_PER_REQUEST,\n",
    "        )\n",
    "\n",
    "        # Append to file\n",
    "        embeddings_formatted = [\n",
    "            json.dumps(\n",
    "                {\n",
    "                    \"id\": str(id),\n",
    "                    \"embedding\": [\n",
    "                        str(value) for value in embedding\n",
    "                    ],\n",
    "                    \"restricts\": [\n",
    "                        {\"namespace\": \"tags\", \"allow\": [str(tag_r)]}\n",
    "                    ],\n",
    "                    \"numeric_restricts\": [\n",
    "                        {\"namespace\": \"score\", \"value_int\": int(score)}\n",
    "                    ],\n",
    "                    \"crowding_tag\": str(tag_crowd)\n",
    "                }\n",
    "            )\n",
    "            + \"\\n\"\n",
    "            # for id, embedding in zip(id_chunk[is_successful], question_chunk_embeddings)\n",
    "            for id, embedding, tag_r, score, tag_crowd in zip(\n",
    "                id_chunk[is_successful], \n",
    "                question_chunk_embeddings, \n",
    "                tags_restrict, \n",
    "                scores_chunk, \n",
    "                tags_crowd\n",
    "            )\n",
    "        ]\n",
    "        f.writelines(embeddings_formatted)\n",
    "\n",
    "        # Delete the DataFrame and any other large data structures\n",
    "        del df\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3b4124-8bc1-4eb3-ab9b-8598504c1e10",
   "metadata": {},
   "source": [
    "#### example output\n",
    "\n",
    "a single `embeddings_formatted` entry should resemble:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"id\": \"67574726\", \n",
    "    \"embedding\": [\n",
    "        \"0.875, ..., 1.000\"\n",
    "    ], \n",
    "    \"restricts\": [\n",
    "        {\"namespace\": \"tags\", \"allow\": [\"c#\"]}\n",
    "    ], \n",
    "    \"numeric_restricts\": [\n",
    "        {\"namespace\": \"score\", \"value_int\": 1}\n",
    "    ],\n",
    "    \"crowding_tag\": \"c#\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f230e61-fd88-4a24-b847-536ceed98ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "18734\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings_formatted))\n",
    "print(len(embeddings_formatted[0]))\n",
    "# embeddings_formatted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c08a93b0-025d-4ef2-9af3-9944116d7343",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOTE_GCS_FOLDER: gs://vvs-vectorio-pubv2-hybrid-vertex/vvs-vectorio-pubv2/embedding_indexes/tmp7wy_c7yy/\n"
     ]
    }
   ],
   "source": [
    "REMOTE_GCS_FOLDER = f\"{BUCKET_URI}/{PREFIX}/embedding_indexes/{embeddings_file_path.stem}/\"\n",
    "print(f\"REMOTE_GCS_FOLDER: {REMOTE_GCS_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf959860-dc17-4254-823d-2db0c6a592bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///var/tmp/tmp7wy_c7yy/tmp7wy_c7yy_0.json [Content-Type=application/json]...\n",
      "/ [1/1 files][  1.8 MiB/  1.8 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/1.8 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "! gsutil -m cp -r {embeddings_file_path}/* {REMOTE_GCS_FOLDER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e1986cc-4513-427a-b9c6-9961ac94b83d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://vvs-vectorio-pubv2-hybrid-vertex/vvs-vectorio-pubv2/embedding_indexes/tmp7wy_c7yy/tmp7wy_c7yy_0.json\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls $REMOTE_GCS_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60c68ee-c660-40b6-b10b-2dbd5fc71776",
   "metadata": {},
   "source": [
    "# Create Vertex Vector Search index and endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36d37b9-58a7-4229-a46e-a914a0cf9750",
   "metadata": {},
   "source": [
    "## Create VS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50820c8d-4ebc-4110-bac1-0e4e13938ac4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CREATE_NEW_VS_INDEX = True\n",
    "\n",
    "# !gcloud ai indexes list \\\n",
    "#   --project=$PROJECT_ID \\\n",
    "#   --region=$REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "543f9d21-b75c-48d3-bb8b-d58bb4d5a084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if using exsiting index\n",
    "if not CREATE_NEW_VS_INDEX:\n",
    "    EXISTING_INDEX_ID = \"..TODO..\"\n",
    "    EXISTING_INDEX_NAME = f'projects/{PROJECT_NUM}/locations/{REGION}/indexes/{EXISTING_INDEX_ID}'\n",
    "    print(f\"EXISTING_INDEX_NAME  : {EXISTING_INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "093fd1fd-d9b7-4d4e-83f5-c1fb2d03af41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPROX_NEIGHBORS          : 150\n",
      "DISTANCE_MEASURE          : DOT_PRODUCT_DISTANCE\n",
      "LEAF_NODE_EMB_COUNT       : 500\n",
      "LEAF_NODES_SEARCH_PERCENT : 80\n",
      "DIMENSIONS                : 768\n",
      "INDEX_UPDATE_METHOD       : 2\n",
      "DISPLAY_NAME              : soverflow_vvs_vectorio_pubv2\n",
      "DESCRIPTION               : sample index for vectorio demo\n"
     ]
    }
   ],
   "source": [
    "# ANN index config\n",
    "APPROX_NEIGHBORS           = 150\n",
    "DISTANCE_MEASURE           = \"DOT_PRODUCT_DISTANCE\"\n",
    "LEAF_NODE_EMB_COUNT        = 500\n",
    "LEAF_NODES_SEARCH_PERCENT  = 80\n",
    "# DIMENSIONS                 = 768\n",
    "INDEX_UPDATE_METHOD        = \"STREAM_UPDATE\"\n",
    "\n",
    "DISPLAY_NAME = f\"soverflow_{PREFIX}\".replace(\"-\",\"_\")\n",
    "DESCRIPTION = \"sample index for vectorio demo\"\n",
    "\n",
    "print(f\"APPROX_NEIGHBORS          : {APPROX_NEIGHBORS}\")\n",
    "print(f\"DISTANCE_MEASURE          : {DISTANCE_MEASURE}\")\n",
    "print(f\"LEAF_NODE_EMB_COUNT       : {LEAF_NODE_EMB_COUNT}\")\n",
    "print(f\"LEAF_NODES_SEARCH_PERCENT : {LEAF_NODES_SEARCH_PERCENT}\")\n",
    "print(f\"DIMENSIONS                : {DIMENSIONS}\")\n",
    "print(f\"INDEX_UPDATE_METHOD       : {INDEX_UPDATE_METHOD}\")\n",
    "print(f\"DISPLAY_NAME              : {DISPLAY_NAME}\")\n",
    "print(f\"DESCRIPTION               : {DESCRIPTION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3c622c1-43e7-442f-afb3-43a4eaee4360",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new index: soverflow_vvs_vectorio_pubv2 ...\n",
      "elapsed time: 18.084052801132202\n",
      "DISPLAY_NAME        : soverflow_vvs_vectorio_pubv2\n",
      "check display_name  : soverflow_vvs_vectorio_pubv2\n",
      "\n",
      "INDEX_RESOURCE_NAME : projects/934903580331/locations/us-central1/indexes/7264767993832275968\n"
     ]
    }
   ],
   "source": [
    "if CREATE_NEW_VS_INDEX:\n",
    "    \n",
    "    print(f\"Creating new index: {DISPLAY_NAME} ...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    tree_ah_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "        display_name=DISPLAY_NAME,\n",
    "        contents_delta_uri=REMOTE_GCS_FOLDER,\n",
    "        dimensions=DIMENSIONS,\n",
    "        approximate_neighbors_count=APPROX_NEIGHBORS,\n",
    "        distance_measure_type=DISTANCE_MEASURE,\n",
    "        leaf_node_embedding_count=LEAF_NODE_EMB_COUNT,\n",
    "        leaf_nodes_to_search_percent=LEAF_NODES_SEARCH_PERCENT,\n",
    "        description=DESCRIPTION,\n",
    "        index_update_method=INDEX_UPDATE_METHOD,\n",
    "        sync=True,\n",
    "        labels={\n",
    "            \"prefix\": f'{PREFIX}',\n",
    "        },\n",
    "    )\n",
    "    end = time.time()\n",
    "    print(f\"elapsed time: {end - start}\")\n",
    "else:\n",
    "    tree_ah_index = aiplatform.MatchingEngineIndex(EXISTING_INDEX_NAME)\n",
    "    \n",
    "INDEX_RESOURCE_NAME = tree_ah_index.resource_name\n",
    "\n",
    "print(f\"DISPLAY_NAME        : {tree_ah_index.display_name}\\n\")\n",
    "print(f\"INDEX_RESOURCE_NAME : {INDEX_RESOURCE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca9f77fb-f3ba-4fb0-8312-347a0c74ff97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/934903580331/locations/us-central1/indexes/7264767993832275968',\n",
       " 'displayName': 'soverflow_vvs_vectorio_pubv2',\n",
       " 'description': 'sample index for vectorio demo',\n",
       " 'metadataSchemaUri': 'gs://google-cloud-aiplatform/schema/matchingengine/metadata/nearest_neighbor_search_1.0.0.yaml',\n",
       " 'metadata': {'config': {'dimensions': 768.0,\n",
       "   'approximateNeighborsCount': 150.0,\n",
       "   'distanceMeasureType': 'DOT_PRODUCT_DISTANCE',\n",
       "   'algorithmConfig': {'treeAhConfig': {'leafNodeEmbeddingCount': '500',\n",
       "     'leafNodesToSearchPercent': 80.0}},\n",
       "   'shardSize': 'SHARD_SIZE_MEDIUM'}},\n",
       " 'etag': 'AMEw9yM-qUn2SNdvuQMsHCRK5yySxjExQqVz3XgPmhye_4Bu8GZjw7O1Mj6DZgTFXoc=',\n",
       " 'labels': {'prefix': 'vvs-vectorio-pubv2'},\n",
       " 'createTime': '2024-01-30T03:36:56.951497Z',\n",
       " 'updateTime': '2024-01-30T03:37:10.208162Z',\n",
       " 'indexStats': {'vectorsCount': '100', 'shardsCount': 1},\n",
       " 'indexUpdateMethod': 'STREAM_UPDATE',\n",
       " 'encryptionSpec': {}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_ah_index.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04bbdf3-a45d-472a-a89c-c5db656ed1e1",
   "metadata": {},
   "source": [
    "*list all indexes:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da7a224-0188-426c-8f8e-5d472282bdac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/934903580331/locations/us-central1/indexes/7264767993832275968'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_indices = tree_ah_index.list()\n",
    "list_of_indices[0].resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc4c4df-dffe-486f-b732-a793ac3ac5e2",
   "metadata": {},
   "source": [
    "*Using the resource name, you can retrieve an existing MatchingEngineIndex:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f0b15e04-df33-4d15-b1b0-0ebc79d8a417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tree_ah_index = aiplatform.MatchingEngineIndex(index_name=INDEX_RESOURCE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d429ac-38d5-4aad-8a65-ccb574950765",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Troubleshooting\n",
    "\n",
    "If index creation fails, grab `OPERATION_ID` and `FAILED_INDEX_ID` from the operation resource name in the error message, for example:\n",
    "\n",
    "> `Please check the details in the metadata of operation: projects/934903580331/locations/us-central1/indexes/FAILED_INDEX_ID/operations/OPERATION_ID.`\n",
    "\n",
    "Then, use `gcloud ai operations describe` to get the error details:\n",
    "\n",
    "```\n",
    "!gcloud ai operations describe $OPERATION_ID \\\n",
    "    --index=$FAILED_INDEX_ID \\\n",
    "    --project=$PROJECT_ID \\\n",
    "    --region=$REGION\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19e45ce9-6b7d-416c-a1ae-c1306cad2a0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OPERATION_ID    = \"2710742495469240320\"\n",
    "# FAILED_INDEX_ID = \"4846053518957608960\"\n",
    "\n",
    "# !gcloud ai operations describe $OPERATION_ID \\\n",
    "#     --index=$FAILED_INDEX_ID \\\n",
    "#     --project=$PROJECT_ID \\\n",
    "#     --region=$REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c666049-67ed-444a-b992-9dc027688ed8",
   "metadata": {},
   "source": [
    "## Create VS Index Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0a8fe71c-389e-40b8-8b67-5587b1f52875",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CREATE_NEW_VS_INDEX_ENDPOINT = True\n",
    "\n",
    "# !gcloud ai index-endpoints list \\\n",
    "#   --project=$PROJECT_ID \\\n",
    "#   --region=$REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89750e14-99ea-44e7-b6db-e8555b734be1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if using exsiting index endpoint\n",
    "if not CREATE_NEW_VS_INDEX_ENDPOINT:\n",
    "    EXISTING_ENDPOINT_ID = \"..TODO..\"\n",
    "    EXISTING_ENDPOINT_NAME = f'projects/{PROJECT_NUM}/locations/{REGION}/indexEndpoints/{EXISTING_ENDPOINT_ID}'\n",
    "    print(f\"EXISTING_ENDPOINT_NAME  : {EXISTING_ENDPOINT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "350805a0-bd2c-4ba2-b05b-69995760d380",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENDPOINT_DISPLAY_NAME : soverflow_vvs_vectorio_pubv2_endpoint\n",
      "ENDPOINT_DESCRIPTION  : index endpoint for vectorio demo\n",
      "USE_PUBLIC_ENDPOINTS  : True\n"
     ]
    }
   ],
   "source": [
    "ENDPOINT_DISPLAY_NAME = f'{DISPLAY_NAME}_endpoint'\n",
    "ENDPOINT_DESCRIPTION  = \"index endpoint for vectorio demo\"\n",
    "\n",
    "# USE_PUBLIC_ENDPOINTS  = True\n",
    "\n",
    "print(f\"ENDPOINT_DISPLAY_NAME : {ENDPOINT_DISPLAY_NAME}\")\n",
    "print(f\"ENDPOINT_DESCRIPTION  : {ENDPOINT_DESCRIPTION}\")\n",
    "print(f\"USE_PUBLIC_ENDPOINTS  : {USE_PUBLIC_ENDPOINTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b58d8f91-eec4-41be-88e1-8a470384306a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new index endpoint: soverflow_vvs_vectorio_pubv2_endpoint ...\n",
      "elapsed time: 1.221855878829956\n",
      "ENDPOINT_DISPLAY_NAME  : soverflow_vvs_vectorio_pubv2_endpoint\n",
      "check display_name     : soverflow_vvs_vectorio_pubv2_endpoint\n",
      "\n",
      "VPC_NETWORK_FULL       : projects/934903580331/global/networks/\n",
      "ENDPOINT_RESOURCE_NAME : projects/934903580331/locations/us-central1/indexEndpoints/5915095480504680448\n"
     ]
    }
   ],
   "source": [
    "if CREATE_NEW_VS_INDEX_ENDPOINT:\n",
    "    \n",
    "    print(f\"Creating new index endpoint: {ENDPOINT_DISPLAY_NAME} ...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "        display_name=ENDPOINT_DISPLAY_NAME,\n",
    "        description=ENDPOINT_DESCRIPTION,\n",
    "        network=VPC_NETWORK_FULL if not USE_PUBLIC_ENDPOINTS else None,\n",
    "        public_endpoint_enabled=USE_PUBLIC_ENDPOINTS,\n",
    "        sync=True,\n",
    "        labels={\n",
    "            \"prefix\": f'{PREFIX}',\n",
    "        },\n",
    "    )\n",
    "    end = time.time()\n",
    "    print(f\"elapsed time: {end - start}\")\n",
    "else:\n",
    "    my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(EXISTING_ENDPOINT_NAME)\n",
    "    \n",
    "ENDPOINT_RESOURCE_NAME = my_index_endpoint.resource_name\n",
    "\n",
    "print(f\"ENDPOINT_DISPLAY_NAME  : {ENDPOINT_DISPLAY_NAME}\")\n",
    "print(f\"check display_name     : {my_index_endpoint.display_name}\\n\")\n",
    "print(f\"VPC_NETWORK_FULL       : {VPC_NETWORK_FULL}\")\n",
    "print(f\"ENDPOINT_RESOURCE_NAME : {ENDPOINT_RESOURCE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bd309f-ca04-4b4b-818c-a990ce258b5e",
   "metadata": {},
   "source": [
    "## Deploy Indexes\n",
    "\n",
    "* [src](https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/matching_engine/matching_engine_index_endpoint.py#L822)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "02de86f2-c272-4e28-902d-78812daac8c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEPLOY_NEW_VS_INDEX = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ccb6d9ca-8561-446b-afaa-1dc64ee80fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if using exsiting deployed index\n",
    "if not DEPLOY_NEW_VS_INDEX:\n",
    "    EXISTING_DEPLOYED_INDEX_ID = \"..TODO..\"\n",
    "    EXISTING_DEPLOYED_INDEX_NAME = f'projects/{PROJECT_NUM}/locations/{REGION}/indexEndpoints/{EXISTING_DEPLOYED_INDEX_ID}'\n",
    "    print(f\"EXISTING_DEPLOYED_INDEX_NAME  : {EXISTING_DEPLOYED_INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4f0adcf2-3d1f-4894-87d3-1e7c51d7a3ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPLOYED_INDEX_ID : deployed_20240130_034024\n",
      "MIN_REPLICAS      : 1\n",
      "MAX_REPLICAS      : 1\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "TIMESTAMP = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "DEPLOYED_INDEX_ID = f'deployed_{TIMESTAMP}'.replace(\"-\",\"_\")\n",
    "# MACHINE_TYPE = \"XXXX\"\n",
    "MIN_REPLICAS = 1\n",
    "MAX_REPLICAS = 1\n",
    "\n",
    "print(f\"DEPLOYED_INDEX_ID : {DEPLOYED_INDEX_ID}\")\n",
    "print(f\"MIN_REPLICAS      : {MIN_REPLICAS}\")\n",
    "print(f\"MAX_REPLICAS      : {MAX_REPLICAS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "34d9fae9-1e9b-4080-b8df-3080d2f26868",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying soverflow_vvs_vectorio_pubv2 to endpoint: soverflow_vvs_vectorio_pubv2_endpoint ...\n",
      "elapsed time: 1547.031239271164\n",
      "DEPLOYED_INDEX_RESOURCE_NAME : projects/934903580331/locations/us-central1/indexEndpoints/5915095480504680448\n",
      "DEPLOYED_INDEX_DISPLAY_NAME  : soverflow_vvs_vectorio_pubv2_endpoint\n"
     ]
    }
   ],
   "source": [
    "if DEPLOY_NEW_VS_INDEX:\n",
    "    \n",
    "    print(f\"Deploying {DISPLAY_NAME} to endpoint: {ENDPOINT_DISPLAY_NAME} ...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    deployed_index = my_index_endpoint.deploy_index(\n",
    "        index=tree_ah_index, \n",
    "        deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "        min_replica_count=MIN_REPLICAS,\n",
    "        max_replica_count=MAX_REPLICAS,\n",
    "        \n",
    "    )\n",
    "    end = time.time()\n",
    "    print(f\"elapsed time: {end - start}\")\n",
    "    \n",
    "else:\n",
    "    deployed_index = aiplatform.MatchingEngineIndexEndpoint(EXISTING_DEPLOYED_INDEX_NAME)\n",
    "\n",
    "DEPLOYED_INDEX_RESOURCE_NAME = deployed_index.resource_name\n",
    "DEPLOYED_INDEX_DISPLAY_NAME  = deployed_index.display_name\n",
    "\n",
    "print(f\"DEPLOYED_INDEX_RESOURCE_NAME : {DEPLOYED_INDEX_RESOURCE_NAME}\")\n",
    "print(f\"DEPLOYED_INDEX_DISPLAY_NAME  : {DEPLOYED_INDEX_DISPLAY_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "163313aa-f0e0-49ac-a732-a898b02a09bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployed indexes on the index endpoint:\n",
      "    deployed_20240130_034024\n"
     ]
    }
   ],
   "source": [
    "print(f\"Deployed indexes on the index endpoint:\")\n",
    "for d in my_index_endpoint.deployed_indexes:\n",
    "    print(f\"    {d.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "06f4d6e9-bd07-4a97-be3b-35245f7cb6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPLOYED_INDEX_ID_TEST : deployed_20240130_034024\n"
     ]
    }
   ],
   "source": [
    "DEPLOYED_INDEX_ID_TEST = deployed_index.deployed_indexes[0].id\n",
    "print(f\"DEPLOYED_INDEX_ID_TEST : {DEPLOYED_INDEX_ID_TEST}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f43da8b-3b02-4097-8d34-75dd3e6698d5",
   "metadata": {},
   "source": [
    "### Confirm matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "58c9e617-2ae4-46cc-969c-c4ba95312c3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 100, Actual: 100\n"
     ]
    }
   ],
   "source": [
    "number_of_vectors = sum(\n",
    "    aiplatform.MatchingEngineIndex(\n",
    "        deployed_index.index\n",
    "    )._gca_resource.index_stats.vectors_count\n",
    "    for deployed_index in my_index_endpoint.deployed_indexes\n",
    ")\n",
    "\n",
    "print(f\"Expected: {BQ_NUM_ROWS}, Actual: {number_of_vectors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c7a227-6130-4e04-ac1c-8ade3a3bed9b",
   "metadata": {},
   "source": [
    "## Create online queries\n",
    "\n",
    "After you build your indexes, you may query against the deployed index to find nearest neighbors.\n",
    "\n",
    "Note: For the `DOT_PRODUCT_DISTANCE` distance type, the \"distance\" property returned with each MatchNeighbor actually refers to the similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7e60c1a6-d0df-405b-b7c0-c6b1ce0a90af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_embeddings = encode_texts_to_embeddings(sentences=[\"Install GPU for Tensorflow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "93ac31c1-00c1-413e-9a5b-043ead1577eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN latency: 0.1461 seconds\n"
     ]
    }
   ],
   "source": [
    "# Test query\n",
    "NUM_NEIGHBOURS = 10\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "response = my_index_endpoint.find_neighbors(\n",
    "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "    queries=test_embeddings,\n",
    "    num_neighbors=NUM_NEIGHBOURS,\n",
    "    return_full_datapoint=True,\n",
    ")\n",
    "\n",
    "elapsed_ann_time = time.time() - start\n",
    "elapsed_ann_time = round(elapsed_ann_time, 4)\n",
    "print(f'ANN latency: {elapsed_ann_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "415b2b9f-948d-47a4-be9f-3c0ad58ae8dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='62031683', distance=0.697461724281311),\n",
       "  MatchNeighbor(id='68085958', distance=0.6485500335693359),\n",
       "  MatchNeighbor(id='73139204', distance=0.6429802179336548),\n",
       "  MatchNeighbor(id='68295202', distance=0.6405211687088013),\n",
       "  MatchNeighbor(id='68127625', distance=0.6347805857658386),\n",
       "  MatchNeighbor(id='61620454', distance=0.6322963237762451),\n",
       "  MatchNeighbor(id='70713265', distance=0.6302939057350159),\n",
       "  MatchNeighbor(id='68352333', distance=0.6260936260223389),\n",
       "  MatchNeighbor(id='65599903', distance=0.6254304647445679),\n",
       "  MatchNeighbor(id='73178654', distance=0.6228378415107727)]]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "444ff335-0d46-4294-94ed-d6649195c56c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN latency: 0.0557 seconds\n"
     ]
    }
   ],
   "source": [
    "# Test query\n",
    "NUM_NEIGHBOURS = 10\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "response = my_index_endpoint.find_neighbors(\n",
    "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "    queries=test_embeddings,\n",
    "    num_neighbors=NUM_NEIGHBOURS,\n",
    "    return_full_datapoint=False,\n",
    ")\n",
    "\n",
    "elapsed_ann_time = time.time() - start\n",
    "elapsed_ann_time = round(elapsed_ann_time, 4)\n",
    "print(f'ANN latency: {elapsed_ann_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "555b219a-334f-441f-84b7-b3bc3b62a1e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[MatchNeighbor(id='62031683', distance=0.697461724281311),\n",
       "  MatchNeighbor(id='68085958', distance=0.6485500335693359),\n",
       "  MatchNeighbor(id='73139204', distance=0.6429802179336548),\n",
       "  MatchNeighbor(id='68295202', distance=0.6405211687088013),\n",
       "  MatchNeighbor(id='68127625', distance=0.6347805857658386),\n",
       "  MatchNeighbor(id='61620454', distance=0.6322963237762451),\n",
       "  MatchNeighbor(id='70713265', distance=0.6302939057350159),\n",
       "  MatchNeighbor(id='68352333', distance=0.6260936260223389),\n",
       "  MatchNeighbor(id='65599903', distance=0.6254304647445679),\n",
       "  MatchNeighbor(id='73178654', distance=0.6228378415107727)]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd96e2b6-1768-47ac-9cd8-7ed036b3c54d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://stackoverflow.com/questions/62031683\n",
      "https://stackoverflow.com/questions/68085958\n",
      "https://stackoverflow.com/questions/73139204\n",
      "https://stackoverflow.com/questions/68295202\n",
      "https://stackoverflow.com/questions/68127625\n",
      "https://stackoverflow.com/questions/61620454\n",
      "https://stackoverflow.com/questions/70713265\n",
      "https://stackoverflow.com/questions/68352333\n",
      "https://stackoverflow.com/questions/65599903\n",
      "https://stackoverflow.com/questions/73178654\n"
     ]
    }
   ],
   "source": [
    "for match_index, neighbor in enumerate(response[0]):\n",
    "    print(f\"https://stackoverflow.com/questions/{neighbor.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8a0a91-f1cc-4d95-8439-d97214274276",
   "metadata": {},
   "source": [
    "### Retrieving metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c68463ad-0981-4156-b8dc-5b9e9c22db0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read_response = my_index_endpoint.read_index_datapoints(\n",
    "#     deployed_index_id=DEPLOYED_INDEX_ID, \n",
    "#     ids= [\"43070568\", \"54122858\"],\n",
    "# )\n",
    "# # read_response\n",
    "# print(f\"crowding_tag       : {read_response[0].crowding_tag}\")\n",
    "# print(f\"crowding_attribute : {read_response[0].crowding_tag.crowding_attribute}\")\n",
    "# print(f\"datapoint_id       : {read_response[0].datapoint_id}\")\n",
    "# print(f\"restricts          : {read_response[0].restricts}\")\n",
    "# print(f\"allow_list         : {read_response[0].restricts[0].allow_list}\")\n",
    "# print(f\"deny_list          : {read_response[0].restricts[0].deny_list}\")\n",
    "# print(f\"namespace          : {read_response[0].restricts[0].namespace}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ecfb75-512d-4545-a484-9a82595504a5",
   "metadata": {},
   "source": [
    "# Clean-up\n",
    "\n",
    "> TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a3b1cb-2632-4f7c-9e64-e6948f324e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# delete_bucket = False\n",
    "\n",
    "# # Force undeployment of indexes and delete endpoint\n",
    "# my_index_endpoint.delete(force=True)\n",
    "\n",
    "# # Delete indexes\n",
    "# tree_ah_index.delete()\n",
    "\n",
    "# if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "#     ! gsutil rm -rf {BUCKET_URI}"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m115"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
