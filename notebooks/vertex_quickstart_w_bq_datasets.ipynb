{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f5960ee-79ab-4a6c-8121-27aa3dc49620",
   "metadata": {},
   "source": [
    "# Quickstart for creating a Vertex Vector Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "342ae23e-4cf1-443f-9d34-34eaecf82403",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/vector-io/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365c2bdf-d117-44b2-ae21-9eac17bfce2e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70a8b170-c9f9-4b5c-af82-148d80de8b65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !gcloud services enable compute.googleapis.com \\\n",
    "#                         aiplatform.googleapis.com \\\n",
    "#                         storage.googleapis.com \\\n",
    "#                         iam.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf747659-9253-4069-8116-36eddb211134",
   "metadata": {},
   "source": [
    "### pip installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2b21b30-2342-4116-9b87-fec08ba3f9ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade --user google-cloud-aiplatform google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "845a13bd-516b-423e-9dc2-a6a8bd204949",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "# import time\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167484a9-df1f-46c0-b14d-3e304a304c29",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed73ba57-6bc8-4979-b2b4-fb4d8527b2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import math\n",
    "import time\n",
    "import json\n",
    "import uuid\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform_v1 as aipv1\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "#python warning \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b24dbcb-7fb3-44b2-a0cf-7e0388bdf205",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 18:34:06.922780: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import pyarrow.parquet as pq\n",
    "from pyarrow import json as pj\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Generator, List, Tuple, Dict, Any, Optional\n",
    "\n",
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "880cdef8-21c6-4158-866a-2d1a32595deb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery SDK version      : 3.15.0\n",
      "Vertex AI SDK version     : 1.39.0\n",
      "Cloud Storage SDK version : 2.14.0\n"
     ]
    }
   ],
   "source": [
    "print(f'BigQuery SDK version      : {bigquery.__version__}')\n",
    "print(f'Vertex AI SDK version     : {aiplatform.__version__}')\n",
    "print(f'Cloud Storage SDK version : {storage.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02310820-8040-43bf-ba8e-cf91426201c4",
   "metadata": {},
   "source": [
    "## Set vars and GCP config\n",
    "\n",
    "`CREATE_NEW_ASSETS`\n",
    "* True creates new GCS buckets and Vector Search instances, etc.\n",
    "* False skips these steps (in case you need to re-run notebook to include new variables you create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4199ef3f-5420-42e3-bae2-7485c7675d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create new gcs bucket, vs index, etc.?\n",
    "CREATE_NEW_ASSETS = False "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b251e02-5ee6-420b-9e62-3a7953d3c6b7",
   "metadata": {},
   "source": [
    "**Edit these to define naming conventions and stay organized across different versions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "034692e0-6ed8-4e50-9aa1-d9a2b11829e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX = vvs-vectorio-pubv3\n"
     ]
    }
   ],
   "source": [
    "# naming convention for all cloud resources\n",
    "VERSION        = \"pubv3\"                     # TODO\n",
    "PREFIX         = f'vvs-vectorio-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX = {PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb883ff-e8df-45e5-a0a3-7068a05f8fb9",
   "metadata": {},
   "source": [
    "### Edit these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c8e240f-58ba-4073-a99d-525b391ddf83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGION    = us-central1\n",
      "BQ_REGION = US\n"
     ]
    }
   ],
   "source": [
    "# locations / regions for cloud resources\n",
    "REGION            = 'us-central1'        \n",
    "BQ_REGION         = 'US'\n",
    "\n",
    "print(f\"REGION    = {REGION}\")\n",
    "print(f\"BQ_REGION = {BQ_REGION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9477c279-b0e9-4fe4-bb07-706676167a19",
   "metadata": {},
   "source": [
    "### Let these populate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b1af4f8-2256-48f6-9ba2-c6f93bd58caa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID       = hybrid-vertex\n",
      "PROJECT_NUM      = 934903580331\n",
      "BUCKET_NAME      = vvs-vectorio-pubv3-hybrid-vertex\n",
      "BUCKET_URI       = gs://vvs-vectorio-pubv3-hybrid-vertex\n",
      "VERTEX_SA        = 934903580331-compute@developer.gserviceaccount.com\n"
     ]
    }
   ],
   "source": [
    "# let these ride\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "PROJECT_NUM              = !gcloud projects describe $PROJECT_ID --format=\"value(projectNumber)\"\n",
    "PROJECT_NUM              = PROJECT_NUM[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "# service account\n",
    "VERTEX_SA                = f'{PROJECT_NUM}-compute@developer.gserviceaccount.com'\n",
    "\n",
    "print(f\"PROJECT_ID       = {PROJECT_ID}\")\n",
    "print(f\"PROJECT_NUM      = {PROJECT_NUM}\")\n",
    "print(f\"BUCKET_NAME      = {BUCKET_NAME}\")\n",
    "print(f\"BUCKET_URI       = {BUCKET_URI}\")\n",
    "print(f\"VERTEX_SA        = {VERTEX_SA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1df1fc4-830c-4d6f-828b-4a040f6c10e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e08dd000-e648-43cb-a129-3a8579521114",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "934903580331-compute@developer.gserviceaccount.com should have access to gs://vvs-vectorio-pubv3-hybrid-vertex\n"
     ]
    }
   ],
   "source": [
    "if CREATE_NEW_ASSETS:\n",
    "    \n",
    "    # create new bucket\n",
    "    ! gsutil mb -l $REGION $BUCKET_URI\n",
    "    \n",
    "    # ### give Service account Admin to GCS\n",
    "    # !gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "    #     --member=serviceAccount:$VERTEX_SA \\\n",
    "    #     --role=roles/storage.admin\n",
    "    \n",
    "    ### uncomment if org policy prevents granting Admin:\n",
    "    # ! gsutil iam ch serviceAccount:{$VERTEX_SA}:roles/storage.objects.get $BUCKET_URI\n",
    "    # ! gsutil iam ch serviceAccount:{$VERTEX_SA}:roles/storage.objects.create $BUCKET_URI\n",
    "    # ! gsutil iam ch serviceAccount:{$VERTEX_SA}:roles/storage.objects.list $BUCKET_URI\n",
    "    \n",
    "    \n",
    "print(f\"{VERTEX_SA} should have access to {BUCKET_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ea47ae-769f-48ac-8c38-ee773285dd57",
   "metadata": {},
   "source": [
    "### Initialize Google Cloud SDK Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c37c0fa-48f0-460c-9541-625c7d298df0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "# bigquery client\n",
    "bq_client = bigquery.Client(\n",
    "    project=PROJECT_ID,\n",
    "    # location=BQ_REGION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43d3cca-9151-4b02-b42f-8351492b244a",
   "metadata": {},
   "source": [
    "# Prepare sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb97bca-516b-4d00-afec-f866f41e391d",
   "metadata": {},
   "source": [
    "You use the [Stack Overflow dataset](https://console.cloud.google.com/marketplace/product/stack-exchange/stack-overflow) of question and answers hosted on BigQuery.\n",
    "\n",
    "> This public dataset is hosted in Google BigQuery and is included in BigQuery's 1TB/mo of free tier processing. This means that each user receives 1TB of free BigQuery processing every month, which can be used to run queries on this public dataset.\n",
    "\n",
    "The BigQuery table is too large to fit into memory, so you need to write a generator called `query_bigquery_chunks` to yield chunks of the dataframe for processing. Additionally, an extra column `title_with_body` is added, which is a concatenation of the question title and body."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1b1cd9-81b6-42be-aa1c-b544aec1d49b",
   "metadata": {},
   "source": [
    "## Query dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0309e862-0f35-42c3-8626-01b607e206c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "QUERY_TEMPLATE = \"\"\"\n",
    "        SELECT DISTINCT q.id, \n",
    "           q.title, \n",
    "           q.body, \n",
    "           q.score, \n",
    "           q.tags,\n",
    "        FROM (\n",
    "            SELECT * FROM `bigquery-public-data.stackoverflow.posts_questions` \n",
    "            WHERE score > 0 \n",
    "            ORDER BY view_count DESC\n",
    "            ) AS q \n",
    "        LIMIT {limit} OFFSET {offset};\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "def query_bigquery_chunks(\n",
    "    max_rows: int, \n",
    "    rows_per_chunk: int, \n",
    "    start_chunk: int = 0\n",
    ") -> Generator[pd.DataFrame, Any, None]:\n",
    "    \n",
    "    for offset in range(start_chunk, max_rows, rows_per_chunk):\n",
    "        query = QUERY_TEMPLATE.format(limit=rows_per_chunk, offset=offset)\n",
    "        query_job = bq_client.query(query)\n",
    "        rows = query_job.result()\n",
    "        df = rows.to_dataframe()\n",
    "        df[\"title_with_body\"] = df.title + \"\\n\" + df.body\n",
    "        df['tags_split_1'] = df['tags'].apply(lambda x: x.split('|', maxsplit=1)[0])\n",
    "        df['tags_split_2'] = df['tags'].apply(lambda x: x.rsplit('|', maxsplit=1)[-1])\n",
    "        df.drop(columns=[\"title\",\"body\",\"tags\"], inplace=True)\n",
    "        yield df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ac4651-b3fa-4302-b70f-b0c26e45b023",
   "metadata": {},
   "source": [
    "### *(Optional)* sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcd64f4f-343d-4513-b5fe-918e1a65d9f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (100, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>title_with_body</th>\n",
       "      <th>tags_split_1</th>\n",
       "      <th>tags_split_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54839558</td>\n",
       "      <td>1</td>\n",
       "      <td>Call JS onsubmit only when form is valid\\n&lt;p&gt;I...</td>\n",
       "      <td>javascript</td>\n",
       "      <td>bootstrap-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54736309</td>\n",
       "      <td>1</td>\n",
       "      <td>How to use output for one function as paramete...</td>\n",
       "      <td>python</td>\n",
       "      <td>parameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54991610</td>\n",
       "      <td>1</td>\n",
       "      <td>How to look up previous values in an R data fr...</td>\n",
       "      <td>r</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  score                                    title_with_body  \\\n",
       "0  54839558      1  Call JS onsubmit only when form is valid\\n<p>I...   \n",
       "1  54736309      1  How to use output for one function as paramete...   \n",
       "2  54991610      1  How to look up previous values in an R data fr...   \n",
       "\n",
       "  tags_split_1 tags_split_2  \n",
       "0   javascript  bootstrap-4  \n",
       "1       python   parameters  \n",
       "2            r            r  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a dataframe of 1000 rows for demonstration purposes\n",
    "df_test = next(\n",
    "    query_bigquery_chunks(\n",
    "        max_rows=100, \n",
    "        rows_per_chunk=100\n",
    "    )\n",
    ")\n",
    "\n",
    "# Examine the data\n",
    "print(f\"df shape: {df_test.shape}\")\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445c687e-8569-4baf-9432-acf37b88f442",
   "metadata": {},
   "source": [
    "### Converting data to embedding vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7522edc2-230a-4877-b845-e3c020a7a790",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### TL;DR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce785f6-92a4-4ae3-87c2-300c76a9442d",
   "metadata": {},
   "source": [
    "**Embedding Vector format for Vertex AI Vector Search**\n",
    "\n",
    "> Understand vector format and available filterting methods, e.g., allow and deny lists, numeric filterting, and crowding (i.e., force diversity in retrieved results\n",
    "\n",
    "**Doc references**\n",
    "* API reference for [IndexDatapoint](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.types.IndexDatapoint)\n",
    "* Vector Search [filtering documentation](https://cloud.google.com/vertex-ai/docs/vector-search/filtering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0322b71-c918-4b87-b5c1-e9082f818347",
   "metadata": {},
   "source": [
    "**embedding_vector**\n",
    "* Encode the file using UTF-8.\n",
    "* Make each line a valid `.json` object to be interpreted as a record.\n",
    "* Include in each record a field named `id` that requires a valid UTF-8 string that is the ID of the vector.\n",
    "* Include in each record a field named embedding that requires an array of numbers. This is the feature vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ea499f-d534-46a3-a35e-403a786dfcc5",
   "metadata": {},
   "source": [
    "Filtering with **String Namespaces**\n",
    "\n",
    "The value of the field `restricts`, if present, should be an array of objects, each is turned into a TokenNamespace in restricts.\n",
    "\n",
    "For each vector's record, add a field called restricts, to contain an array of objects, each of which is a namespace.\n",
    "\n",
    "* Each object must have a field named namespace. This field is the TokenNamespace.namespace, namespace.\n",
    "* The value of the field allow, if present, is an array of strings. This array of strings is the TokenNamespace.string_tokens list.\n",
    "* The value of the field deny, if present, is an array of strings. This array of strings is the TokenNamespace.string_denylist_tokens list.\n",
    "\n",
    "```\n",
    "{\n",
    "    \"id\": \"42\", \n",
    "    \"embedding\": [0.5, 1.0], \n",
    "    \"restricts\": [\n",
    "        {\"namespace\": \"class\",\"allow\": [\"cat\", \"pet\"]},\n",
    "        {\"namespace\": \"category\", \"allow\": [\"feline\"]}\n",
    "    ]\n",
    "}\n",
    "{\n",
    "    \"id\": \"43\", \n",
    "    \"embedding\": [0.6, 1.0], \n",
    "    \"restricts\": [\n",
    "        {\"namespace\": \"class\", \"allow\": [\"dog\", \"pet\"]},\n",
    "        {\"namespace\": \"category\", \"allow\": [\"canine\"]}\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15fa146-9600-464b-8f4f-da0e6d605b10",
   "metadata": {},
   "source": [
    "Filtering with **Numeric namespaces**\n",
    "For each vector's record, add a field called `numeric_restricts`, to contain an array of objects, each of which is a numeric restrict.\n",
    "\n",
    "* Each object must have a field named namespace. This field is the NumericRestrictNamespace.namespace, namespace.\n",
    "* Each object must have one of `value_int`, `value_float`, and `value_double`.\n",
    "* Each object must not have a field named op. This field is only for query.\n",
    "\n",
    "```\n",
    "{\n",
    "    \"id\": \"42\", \n",
    "    \"embedding\": [0.5, 1.0], \n",
    "    \"numeric_restricts\": [\n",
    "        {\"namespace\": \"size\", \"value_int\": 3},\n",
    "        {\"namespace\": \"ratio\", \"value_float\": 0.1}\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fa974b-8893-4aaa-8bdb-755313d41162",
   "metadata": {},
   "source": [
    "**crowding tag**\n",
    "\n",
    "The value of the field `crowding_tag`, if present, should be a string\n",
    "\n",
    "```\n",
    "{\n",
    "    \"id\": \"43\", \n",
    "    \"embedding\": [0.6, 1.0], \n",
    "    \"numeric_restricts\": [\n",
    "        {\"namespace\": \"ratio\", \"value_float\": 0.1}\n",
    "    ],\n",
    "    \"crowding_tag\": \"shoes\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a6d3f3-ba66-464c-8839-2de3c5093f7c",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ef1306c-79e8-4462-9381-4cad42dd2f86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define an embedding method that uses the model\n",
    "def encode_texts_to_embeddings(sentences: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        embeddings = model.get_embeddings(sentences)\n",
    "        return [embedding.values for embedding in embeddings]\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(sentences))]\n",
    "    \n",
    "# Generator function to yield batches of sentences\n",
    "def generate_batches(\n",
    "    sentences: List[str], \n",
    "    batch_size: int\n",
    ") -> Generator[List[str], None, None]:\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        yield sentences[i : i + batch_size]\n",
    "        \n",
    "def encode_text_to_embedding_batched(\n",
    "    sentences: List[str], \n",
    "    api_calls_per_second: int = 10, \n",
    "    batch_size: int = 5\n",
    ") -> Tuple[List[bool], np.ndarray]:\n",
    "\n",
    "    embeddings_list: List[List[float]] = []\n",
    "\n",
    "    # Prepare the batches using a generator\n",
    "    batches = generate_batches(sentences, batch_size)\n",
    "\n",
    "    seconds_per_job = 1 / api_calls_per_second\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for batch in tqdm(\n",
    "            batches, total=math.ceil(len(sentences) / batch_size), position=0\n",
    "        ):\n",
    "            futures.append(\n",
    "                executor.submit(functools.partial(encode_texts_to_embeddings), batch)\n",
    "            )\n",
    "            time.sleep(seconds_per_job)\n",
    "\n",
    "        for future in futures:\n",
    "            embeddings_list.extend(future.result())\n",
    "\n",
    "    is_successful = [\n",
    "        embedding is not None for sentence, embedding in zip(sentences, embeddings_list)\n",
    "    ]\n",
    "    embeddings_list_successful = np.squeeze(\n",
    "        np.stack([embedding for embedding in embeddings_list if embedding is not None])\n",
    "    )\n",
    "    return is_successful, embeddings_list_successful\n",
    "\n",
    "def create_emb_vector_files(\n",
    "    bq_num_rows: int = 1000,\n",
    "    bq_chunk_size: int = 100,\n",
    "    bq_num_chunks: int = 10,\n",
    "    start_chunk: int = 0,\n",
    "    api_calls_per_sec: int = 50,\n",
    "    items_per_request: int = 5,\n",
    "    emb_file_path: str = None\n",
    "):\n",
    "    print(f\"bq_num_rows       : {bq_num_rows}\")\n",
    "    print(f\"bq_chunk_size     : {bq_chunk_size}\")\n",
    "    print(f\"bq_num_chunks     : {bq_num_chunks}\")\n",
    "    print(f\"start_chunk       : {start_chunk}\")\n",
    "    print(f\"api_calls_per_sec : {api_calls_per_sec}\")\n",
    "    print(f\"items_per_request : {items_per_request}\")\n",
    "    print(f\"emb_file_path     : {emb_file_path}\")\n",
    "    \n",
    "    rows_list = []\n",
    "    \n",
    "    # Loop through each generated dataframe, convert\n",
    "    for i, df in tqdm(\n",
    "        enumerate(\n",
    "            query_bigquery_chunks(\n",
    "                max_rows=bq_num_rows, \n",
    "                rows_per_chunk=bq_chunk_size, \n",
    "                start_chunk=start_chunk\n",
    "            )\n",
    "        ),\n",
    "        total=bq_num_chunks,# - start_chunk,\n",
    "        position=-1,\n",
    "        desc=\"Chunk of rows from BigQuery\",\n",
    "    ):\n",
    "        \n",
    "        print(f\"Starting: {i} of {bq_num_chunks} loops\")\n",
    "        \n",
    "        # Create a unique output file for each chunk\n",
    "        chunk_path = emb_file_path.joinpath(\n",
    "            f\"{emb_file_path.stem}_{i+start_chunk}.json\"\n",
    "        )\n",
    "        with open(chunk_path, \"a\") as f:\n",
    "        \n",
    "            id_chunk = df.id\n",
    "            scores_chunk = df.score\n",
    "            tags_1_chunk = df.tags_split_1\n",
    "            tags_2_chunk = df.tags_split_2\n",
    "\n",
    "            # Convert batch to embeddings\n",
    "            is_successful, question_chunk_embeddings = encode_text_to_embedding_batched(\n",
    "                sentences=df.title_with_body.tolist(), #[:500]\n",
    "                api_calls_per_second=api_calls_per_sec,\n",
    "                batch_size=items_per_request,\n",
    "            )\n",
    "\n",
    "            embeddings_formatted = [\n",
    "                json.dumps(\n",
    "                    {\n",
    "                        \"id\": str(id),\n",
    "                        \"embedding\": [\n",
    "                            str(value) for value in embedding\n",
    "                        ],\n",
    "                        \"tag\": str(r_tag),               # restricts_allow\n",
    "                        \"score\": int(score),             # numeric_restricts\n",
    "                        \"crowding_tag\": str(c_tag)\n",
    "                    }\n",
    "                )\n",
    "                + \"\\n\"\n",
    "                for id, embedding, r_tag, score, c_tag in zip(\n",
    "                    id_chunk[is_successful], \n",
    "                    question_chunk_embeddings, \n",
    "                    tags_1_chunk, \n",
    "                    scores_chunk, \n",
    "                    tags_2_chunk\n",
    "                )\n",
    "            ]\n",
    "            f.writelines(embeddings_formatted)\n",
    "\n",
    "            print(f\"tags_1_chunk              : {len(tags_1_chunk)}\")\n",
    "            print(f\"tags_2_chunk              : {len(tags_2_chunk)}\")\n",
    "            print(f\"scores_chunk              : {len(scores_chunk)}\")\n",
    "            print(f\"question_chunk_embeddings : {len(question_chunk_embeddings)}\")\n",
    "            print(f\"id_chunk[is_successful]   : {len(id_chunk[is_successful])}\")\n",
    "\n",
    "            # Delete the DataFrame and any other large data structures\n",
    "            del df\n",
    "            gc.collect()\n",
    "    \n",
    "    print(\"loops complete...\\n\")\n",
    "    print(f\"len(embeddings_formatted)    : {len(embeddings_formatted)}\")\n",
    "    print(f\"len(embeddings_formatted[0]) : {len(embeddings_formatted[0])}\")\n",
    "    \n",
    "    return embeddings_formatted[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea07b3-84f5-45cc-988e-b9035602a3e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Test helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5030e7cb-7061-463b-9fa9-2d8d591232d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Encode a subset of questions for validation\n",
    "# questions = df_test.title.tolist()[:50]\n",
    "\n",
    "# is_successful, question_embeddings = encode_text_to_embedding_batched(\n",
    "#     sentences=df.title.tolist()[:50],\n",
    "# )\n",
    "# print(question_embeddings.shape)\n",
    "\n",
    "# DIMENSIONS = len(question_embeddings[0])\n",
    "# print(DIMENSIONS)\n",
    "\n",
    "# # Filter for successfully embedded sentences\n",
    "# questions = np.array(questions)[is_successful]\n",
    "\n",
    "# print(questions.shape)\n",
    "# questions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cbeb06-c468-42b0-ab8f-1abf1fe4338d",
   "metadata": {},
   "source": [
    "### Create Vector Embedding json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c8c4dad9-ec33-4018-9000-40fdbf82fc8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb_json_file_path: /var/tmp/tmpm4k5k6gq\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import json\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Create temporary file to write embeddings to\n",
    "emb_json_file_path = Path(tempfile.mkdtemp())\n",
    "print(f\"emb_json_file_path: {emb_json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8c1444cd-d38a-4587-b326-9f8ca946fea6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BQ_NUM_CHUNKS     : 5\n",
      "API_CALLS_PER_SEC : 5.0\n"
     ]
    }
   ],
   "source": [
    "BQ_NUM_ROWS       = 5000               # position to stop\n",
    "BQ_CHUNK_SIZE     = 1000                # incrementation\n",
    "NEXT_START        = 2000                  # position to start\n",
    "\n",
    "BQ_NUM_CHUNKS     = math.ceil(BQ_NUM_ROWS / BQ_CHUNK_SIZE)\n",
    "API_CALLS_PER_SEC = 300 / 60\n",
    "\n",
    "print(f\"BQ_NUM_CHUNKS     : {BQ_NUM_CHUNKS}\")\n",
    "print(f\"API_CALLS_PER_SEC : {API_CALLS_PER_SEC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c376f21f-457a-49b5-834c-018d7e89f3c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bq_num_rows       : 5000\n",
      "bq_chunk_size     : 1000\n",
      "bq_num_chunks     : 5\n",
      "start_chunk       : 2000\n",
      "api_calls_per_sec : 5.0\n",
      "items_per_request : 5\n",
      "emb_file_path     : /var/tmp/tmpm4k5k6gq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80234271a24476c8dbe4542bda811f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Chunk of rows from BigQuery:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: 0 of 5 loops\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac40e5966654d50b9a5b092b79dd0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags_1_chunk              : 1000\n",
      "tags_2_chunk              : 1000\n",
      "scores_chunk              : 1000\n",
      "question_chunk_embeddings : 1000\n",
      "id_chunk[is_successful]   : 1000\n",
      "Starting: 1 of 5 loops\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8737c14acd804f608d80116611db36f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags_1_chunk              : 1000\n",
      "tags_2_chunk              : 1000\n",
      "scores_chunk              : 1000\n",
      "question_chunk_embeddings : 1000\n",
      "id_chunk[is_successful]   : 1000\n",
      "Starting: 2 of 5 loops\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ec5f6f00d7448db1d8ca3d753c8085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags_1_chunk              : 1000\n",
      "tags_2_chunk              : 1000\n",
      "scores_chunk              : 1000\n",
      "question_chunk_embeddings : 1000\n",
      "id_chunk[is_successful]   : 1000\n",
      "loops complete...\n",
      "\n",
      "len(embeddings_formatted)    : 1000\n",
      "len(embeddings_formatted[0]) : 18638\n"
     ]
    }
   ],
   "source": [
    "sample_formatted_emb = create_emb_vector_files(\n",
    "    bq_num_rows = BQ_NUM_ROWS,\n",
    "    bq_chunk_size = BQ_CHUNK_SIZE,\n",
    "    bq_num_chunks = BQ_NUM_CHUNKS,\n",
    "    start_chunk = NEXT_START,\n",
    "    api_calls_per_sec = API_CALLS_PER_SEC,\n",
    "    items_per_request = 5,\n",
    "    emb_file_path = emb_json_file_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8675855-d26e-4ac0-846d-436ef2469ca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample_formatted_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28440a47-7507-430d-b48e-498dbf3ccf8d",
   "metadata": {},
   "source": [
    "### Save to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "edb20b49-7f73-48be-a2f4-19c684101a5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOTE_GCS_FOLDER: gs://vvs-vectorio-pubv3-hybrid-vertex/vvs-vectorio-pubv3/embedding_indexes/tmpm4k5k6gq/\n"
     ]
    }
   ],
   "source": [
    "REMOTE_GCS_FOLDER = f\"{BUCKET_URI}/{PREFIX}/embedding_indexes/{emb_json_file_path.stem}/\"\n",
    "print(f\"REMOTE_GCS_FOLDER: {REMOTE_GCS_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "19f995d2-d8fa-45c2-a43c-8d8c7972924f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///var/tmp/tmpm4k5k6gq/tmpm4k5k6gq_2001.json [Content-Type=application/json]...\n",
      "Copying file:///var/tmp/tmpm4k5k6gq/tmpm4k5k6gq_2000.json [Content-Type=application/json]...\n",
      "Copying file:///var/tmp/tmpm4k5k6gq/tmpm4k5k6gq_2002.json [Content-Type=application/json]...\n",
      "- [3/3 files][ 53.2 MiB/ 53.2 MiB] 100% Done                                    \n",
      "Operation completed over 3 objects/53.2 MiB.                                     \n",
      "gs://vvs-vectorio-pubv3-hybrid-vertex/vvs-vectorio-pubv3/embedding_indexes/tmpm4k5k6gq/tmpm4k5k6gq_2000.json\n",
      "gs://vvs-vectorio-pubv3-hybrid-vertex/vvs-vectorio-pubv3/embedding_indexes/tmpm4k5k6gq/tmpm4k5k6gq_2001.json\n",
      "gs://vvs-vectorio-pubv3-hybrid-vertex/vvs-vectorio-pubv3/embedding_indexes/tmpm4k5k6gq/tmpm4k5k6gq_2002.json\n"
     ]
    }
   ],
   "source": [
    "! gsutil -m cp -r {emb_json_file_path}/* {REMOTE_GCS_FOLDER}\n",
    "\n",
    "! gsutil ls $REMOTE_GCS_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36338911-b8c7-4e43-9c4b-71c4d4f88c5f",
   "metadata": {},
   "source": [
    "### Write to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fd966113-c132-4cf3-817f-e9c85e23a355",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parquet_file_path: /var/tmp/tmpsgm4txp8\n",
      "SO_PARQUET_GCS_DIR: gs://vvs-vectorio-pubv3-hybrid-vertex/emb_vector_parquet/so_2000_5000_1000/tmpsgm4txp8/\n"
     ]
    }
   ],
   "source": [
    "# Create temporary file to write embeddings to\n",
    "parquet_file_path = Path(tempfile.mkdtemp())\n",
    "print(f\"parquet_file_path: {parquet_file_path}\")\n",
    "\n",
    "EMB_PARQ_GCS_DIR = f\"{BUCKET_URI}/emb_vector_parquet\"\n",
    "SO_PARQUET_GCS_DIR = f\"{EMB_PARQ_GCS_DIR}/so_{NEXT_START}_{BQ_NUM_ROWS}_{BQ_CHUNK_SIZE}/{parquet_file_path.stem}/\"\n",
    "print(f\"SO_PARQUET_GCS_DIR: {SO_PARQUET_GCS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7abe332d-a57f-4c46-99eb-14f7b9e1f40e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved parquet files to: gs://vvs-vectorio-pubv3-hybrid-vertex/emb_vector_parquet/so_2000_5000_1000/tmpsgm4txp8/\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gs://vvs-vectorio-pubv3-hybrid-vertex/emb_vector_parquet/so_2000_5000_1000/tmpsgm4txp8/tmpm4k5k6gq_2001.parquet',\n",
       " 'gs://vvs-vectorio-pubv3-hybrid-vertex/emb_vector_parquet/so_2000_5000_1000/tmpsgm4txp8/tmpm4k5k6gq_2000.parquet',\n",
       " 'gs://vvs-vectorio-pubv3-hybrid-vertex/emb_vector_parquet/so_2000_5000_1000/tmpsgm4txp8/tmpm4k5k6gq_2002.parquet']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARQUET_GCS_FILE_LIST = []\n",
    "\n",
    "for f in emb_json_file_path.iterdir():\n",
    "    \n",
    "    local_f = os.path.abspath(str(f))\n",
    "    dest_file = os.path.join(SO_PARQUET_GCS_DIR, f\"{f.stem}.parquet\")\n",
    "    \n",
    "    # print(f\"reading from: {local_f}\")\n",
    "    table = pj.read_json(local_f)\n",
    "    \n",
    "    # print(f\"saving to: {dest_file}\")\n",
    "    pq.write_table(table, dest_file)\n",
    "    \n",
    "    PARQUET_GCS_FILE_LIST.append(dest_file)\n",
    "    \n",
    "print(f\"saved parquet files to: {SO_PARQUET_GCS_DIR}\\n\")\n",
    "PARQUET_GCS_FILE_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c839bbf4-9097-412d-b2ab-214a1c40dc2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>embedding</th>\n",
       "      <th>tag</th>\n",
       "      <th>score</th>\n",
       "      <th>crowding_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43154170</td>\n",
       "      <td>[-0.024622129276394844, -0.005234652664512396,...</td>\n",
       "      <td>security</td>\n",
       "      <td>16</td>\n",
       "      <td>cors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43441856</td>\n",
       "      <td>[0.01128651574254036, -0.0018839503172785044, ...</td>\n",
       "      <td>javascript</td>\n",
       "      <td>387</td>\n",
       "      <td>ecmascript-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43460880</td>\n",
       "      <td>[-0.04847663268446922, -0.01450541615486145, 0...</td>\n",
       "      <td>unit-testing</td>\n",
       "      <td>20</td>\n",
       "      <td>xunit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43373082</td>\n",
       "      <td>[-0.002033930504694581, -0.05231621116399765, ...</td>\n",
       "      <td>java</td>\n",
       "      <td>11</td>\n",
       "      <td>vaadin7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47416861</td>\n",
       "      <td>[0.006317105144262314, -0.05412781983613968, 0...</td>\n",
       "      <td>python</td>\n",
       "      <td>23</td>\n",
       "      <td>keras-layer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                          embedding           tag  \\\n",
       "0  43154170  [-0.024622129276394844, -0.005234652664512396,...      security   \n",
       "1  43441856  [0.01128651574254036, -0.0018839503172785044, ...    javascript   \n",
       "2  43460880  [-0.04847663268446922, -0.01450541615486145, 0...  unit-testing   \n",
       "3  43373082  [-0.002033930504694581, -0.05231621116399765, ...          java   \n",
       "4  47416861  [0.006317105144262314, -0.05412781983613968, 0...        python   \n",
       "\n",
       "   score  crowding_tag  \n",
       "0     16          cors  \n",
       "1    387  ecmascript-6  \n",
       "2     20         xunit  \n",
       "3     11       vaadin7  \n",
       "4     23   keras-layer  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate parquet files\n",
    "df_from_pq = pd.read_parquet(PARQUET_GCS_FILE_LIST[0])\n",
    "\n",
    "print(df_from_pq.shape)\n",
    "df_from_pq.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b056e9-87d4-40cf-9f60-18d98825a6dd",
   "metadata": {},
   "source": [
    "### Write test sets locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f096c769-2a66-422e-8d59-a745df702db8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOCAL_TEST_DIR = f\"data/stack_overflow_parquet_{VERSION}\"\n",
    "LOCAL_TEST_DATA_DIR = f\"{LOCAL_TEST_DIR}/files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "afa5ff87-c311-4a63-b7ba-90854d1ae1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(LOCAL_TEST_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5588ff61-ea64-40ee-933b-2c31b397d0d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmpm4k5k6gq_2001.parquet\n",
      "tmpm4k5k6gq_2000.parquet\n",
      "tmpm4k5k6gq_2002.parquet\n"
     ]
    }
   ],
   "source": [
    "LOCAL_PARQUEST_FILE_LIST = []\n",
    "\n",
    "for file in PARQUET_GCS_FILE_LIST:\n",
    "\n",
    "    file_name = file.rsplit('/', maxsplit=1)[-1]\n",
    "    print(file_name)\n",
    "    \n",
    "    LOCAL_PARQUET_FILE = f\"{LOCAL_TEST_DATA_DIR}/so_{file_name}\"\n",
    "    \n",
    "    df_tmp = pd.read_parquet(file)\n",
    "    df_tmp.to_parquet(LOCAL_PARQUET_FILE)\n",
    "    \n",
    "    LOCAL_PARQUEST_FILE_LIST.append(LOCAL_PARQUET_FILE)\n",
    "    \n",
    "    # Delete the DataFrame and any other large data structures\n",
    "    del df_tmp\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6531c59d-5982-4ffe-beb7-9564e3988aa4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/stack_overflow_parquet_pubv3/files/so_tmpm4k5k6gq_2001.parquet',\n",
       " 'data/stack_overflow_parquet_pubv3/files/so_tmpm4k5k6gq_2000.parquet',\n",
       " 'data/stack_overflow_parquet_pubv3/files/so_tmpm4k5k6gq_2002.parquet']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOCAL_PARQUEST_FILE_LIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f575c2-f62b-4a5c-977f-701e6a12b7b8",
   "metadata": {},
   "source": [
    "# Create Vector Search Index, and deploy to Index Endpoint\n",
    "\n",
    "> This will create an index with a single vector; use this to test the import and export classes\n",
    "\n",
    "Steps:\n",
    "1. Create single dummy embedding vector to create Vector Search index\n",
    "2. Create index endpoint\n",
    "3. deploy index to index endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6e8bb5-9ba8-4baf-9980-6d786441f1f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TL;DR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00118d57-1e52-4453-9cea-81258f8e6b29",
   "metadata": {},
   "source": [
    "**VS Index Config**\n",
    "* Set index's update method for *streaming updates*\n",
    "* See [Create and manage your index](https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index) documentation to better understand `Shard sizes` and the `machine types` available\n",
    "* See [Tuning the index](https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index#tuning_the_index) documentation to learn how config parameters impact recall and latency\n",
    "\n",
    "**VS Index Endpoint Config**\n",
    "* Use public endpoints unless VPC is a networking requirement\n",
    "\n",
    "**VS Deployed Index ID**: `deployed_index_id` (str) \n",
    "* Required. The user specified ID of the `DeployedIndex`\n",
    "* can be up to 128 characters long, \n",
    "* must start with a letter and only contain letters, numbers, and underscores.\n",
    "* The ID must be unique within the project it is created in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363c65fb-5639-4377-97bc-5415da045116",
   "metadata": {},
   "source": [
    "`VPC_NETWORK_NAME`\n",
    "* if index will be **deployed to a private endpoint** within a VPC network, edit this with the name of your VPC network name\n",
    "* if index will be **deployed to a public endpoint**, leave blank\n",
    "\n",
    "> For details on configuring VPC for Vertex AI Vector Search, see **[Set up a VPC Network Peering connection](https://cloud.google.com/vertex-ai/docs/vector-search/setup/vpc)**\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>⚠️ if deploying index to index endpoint within a VPC network, you must interact with the index endpoint from within the VPC network, i.e., run this notebook in a Vertex Workbench instance within that VPC ⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbb5494-2a21-4973-86d5-4818089650ae",
   "metadata": {},
   "source": [
    "## Index and Endpoint config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9bbbe7fd-91e0-4071-a422-beac27fe20df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.protobuf import struct_pb2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6666599-9802-4949-8890-860e9f2993ef",
   "metadata": {},
   "source": [
    "*To list current indexes*\n",
    "\n",
    "```\n",
    "!gcloud ai indexes list --project=$PROJECT_ID --region=$REGION\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec2198fc-5e5b-4667-9944-bff79f48f275",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXISTING_INDEX_NAME  : projects/934903580331/locations/us-central1/indexes/1081325705452584960\n"
     ]
    }
   ],
   "source": [
    "CREATE_NEW_VS_INDEX = False\n",
    "\n",
    "# if using exsiting index\n",
    "if not CREATE_NEW_VS_INDEX:\n",
    "    EXISTING_INDEX_ID = \"1081325705452584960\" # TODO\n",
    "    EXISTING_INDEX_NAME = f'projects/{PROJECT_NUM}/locations/{REGION}/indexes/{EXISTING_INDEX_ID}'\n",
    "    print(f\"EXISTING_INDEX_NAME  : {EXISTING_INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "16c1f289-a31f-4dbf-8b8d-4c882e5c22f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE_PUBLIC_ENDPOINTS = True\n"
     ]
    }
   ],
   "source": [
    "# specify VPC network or leave blank\n",
    "VPC_NETWORK_NAME             = \"\"  # e.g., \"your-vpc-name\" | \"\"\n",
    "\n",
    "if VPC_NETWORK_NAME:\n",
    "    USE_PUBLIC_ENDPOINTS     = False\n",
    "    # full VPC network name\n",
    "    VPC_NETWORK_FULL         = f\"projects/{PROJECT_NUM}/global/networks/{VPC_NETWORK_NAME}\"\n",
    "    print(f\"VPC_NETWORK_NAME : {VPC_NETWORK_NAME}\")\n",
    "    print(f\"VPC_NETWORK_FULL : {VPC_NETWORK_FULL}\")\n",
    "else:\n",
    "    USE_PUBLIC_ENDPOINTS     = True\n",
    "    VPC_NETWORK_FULL         = None\n",
    "\n",
    "print(f\"USE_PUBLIC_ENDPOINTS = {USE_PUBLIC_ENDPOINTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fa5963cf-e02e-4d4a-991d-d804a43d040b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENDPOINT_DISPLAY_NAME : soverflow_vvs_vectorio_pubv3_endpoint\n",
      "ENDPOINT_DESCRIPTION  : index endpoint for vectorio demo\n",
      "USE_PUBLIC_ENDPOINTS  : True\n",
      "DEPLOYED_INDEX_ID     : soverflow_vvs_vectorio_pubv3_20240130131739\n",
      "# characters (< 128)  : 43\n",
      "MACHINE_TYPE          : e2-standard-16\n",
      "MIN_REPLICAS          : 1\n",
      "MAX_REPLICAS          : 1\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# ANN index config\n",
    "# =========================================================\n",
    "DISPLAY_NAME        = f\"soverflow_{PREFIX}\".replace(\"-\",\"_\")\n",
    "DESCRIPTION         = \"sample index for vectorio demo\"\n",
    "APPROX_NEIGHBORS    = 150\n",
    "DISTANCE_MEASURE    = \"DOT_PRODUCT_DISTANCE\"\n",
    "LEAF_NODE_EMB_COUNT = 500\n",
    "LEAF_SEARCH_PERCENT = 80\n",
    "DIMENSIONS          = 768\n",
    "INDEX_UPDATE_METHOD = aipv1.Index.IndexUpdateMethod.STREAM_UPDATE # \"STREAM_UPDATE\"\n",
    "INDEX_SHARD_SIZE    = \"SHARD_SIZE_MEDIUM\"\n",
    "\n",
    "# =========================================================\n",
    "# index endpoint config\n",
    "# =========================================================\n",
    "ENDPOINT_DISPLAY_NAME = f'{DISPLAY_NAME}_endpoint'\n",
    "ENDPOINT_DESCRIPTION  = \"index endpoint for vectorio demo\"\n",
    "print(f\"ENDPOINT_DISPLAY_NAME : {ENDPOINT_DISPLAY_NAME}\")\n",
    "print(f\"ENDPOINT_DESCRIPTION  : {ENDPOINT_DESCRIPTION}\")\n",
    "print(f\"USE_PUBLIC_ENDPOINTS  : {USE_PUBLIC_ENDPOINTS}\")\n",
    "\n",
    "# =========================================================\n",
    "# Deployed index\n",
    "# =========================================================\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "DEPLOYED_INDEX_ID = f\"{DISPLAY_NAME.replace('-', '_')}_{timestamp}\"\n",
    "MACHINE_TYPE      = \"e2-standard-16\"\n",
    "MIN_REPLICAS      = 1\n",
    "MAX_REPLICAS      = 1\n",
    "print(f\"DEPLOYED_INDEX_ID     : {DEPLOYED_INDEX_ID}\")\n",
    "print(f\"# characters (< 128)  : {len(DEPLOYED_INDEX_ID)}\")\n",
    "print(f\"MACHINE_TYPE          : {MACHINE_TYPE}\")\n",
    "print(f\"MIN_REPLICAS          : {MIN_REPLICAS}\")\n",
    "print(f\"MAX_REPLICAS          : {MAX_REPLICAS}\")\n",
    "\n",
    "# =========================================================\n",
    "# set index client\n",
    "# =========================================================\n",
    "project_config = {\n",
    "    \"region\": REGION,\n",
    "    \"project_id\": PROJECT_ID,\n",
    "}\n",
    "endpoint = \"{}-aiplatform.googleapis.com\".format(project_config[\"region\"])\n",
    "index_client = aipv1.IndexServiceClient(\n",
    "    client_options=dict(api_endpoint=endpoint)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26423216-0f9a-4260-8338-7c28072ad0a1",
   "metadata": {},
   "source": [
    "## Create dummy data for index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0f6ac9a-ddb5-459f-a675-2d2702f76753",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTENTS_URI           : gs://vvs-vectorio-pubv3-hybrid-vertex/init_index\n",
      "EMBEDDING_BLOB_NAME    : init_index/embeddings_0.json\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# initial emb vector\n",
    "# =========================================================\n",
    "LOCAL_INIT_FILE = \"embeddings_0.json\"\n",
    "CONTENTS_EMB_DIR = \"init_index\"\n",
    "\n",
    "EMBEDDING_BLOB_NAME = f\"{CONTENTS_EMB_DIR}/{LOCAL_INIT_FILE}\"\n",
    "CONTENTS_URI = f\"{BUCKET_URI}/{CONTENTS_EMB_DIR}\"\n",
    "\n",
    "print(f\"CONTENTS_URI           : {CONTENTS_URI}\")\n",
    "print(f\"EMBEDDING_BLOB_NAME    : {EMBEDDING_BLOB_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1590d9b3-0b1a-4b56-8596-e705ca2e9c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CREATE_NEW_VS_INDEX:\n",
    "    \n",
    "    # dummy embedding\n",
    "    init_embedding = {\n",
    "        \"id\": str(uuid.uuid4()),\n",
    "        \"embedding\": list(np.zeros(DIMENSIONS))\n",
    "    }\n",
    "\n",
    "    # dump embedding to a local file\n",
    "    with open(LOCAL_INIT_FILE, \"w\") as f:\n",
    "        json.dump(init_embedding, f)\n",
    "\n",
    "    # write embedding to Cloud Storage\n",
    "    ! gsutil cp $LOCAL_INIT_FILE $CONTENTS_URI/$LOCAL_INIT_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aa93af5f-d060-4ae1-b03f-5667881e4024",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://vvs-vectorio-pubv3-hybrid-vertex/init_index/embeddings_0.json\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $CONTENTS_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90751669-f212-460c-8e69-de0eb77a74de",
   "metadata": {},
   "source": [
    "## Define Index Configuration Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f5c9dde-2877-4dbd-b6ff-9bb0bbed3fd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index_display_name': 'soverflow_vvs_vectorio_pubv3',\n",
       " 'contents_delta_uri': 'gs://vvs-vectorio-pubv3-hybrid-vertex/init_index',\n",
       " 'dimensions': 768,\n",
       " 'approximate_neighbors_count': 150,\n",
       " 'distance_measure_type': 'DOT_PRODUCT_DISTANCE',\n",
       " 'leaf_node_embedding_count': 500,\n",
       " 'leaf_nodes_to_search_percent': 80,\n",
       " 'index_shard_size': 'SHARD_SIZE_MEDIUM',\n",
       " 'index_update_method': <IndexUpdateMethod.STREAM_UPDATE: 2>,\n",
       " 'description': 'sample index for vectorio demo',\n",
       " 'labels': {'prefix': 'vvs-vectorio-pubv3'},\n",
       " 'index_endpoint_display_name': 'soverflow_vvs_vectorio_pubv3_endpoint',\n",
       " 'index_endpoint_description': 'index endpoint for vectorio demo',\n",
       " 'deployed_index_id': 'soverflow_vvs_vectorio_pubv3_20240130192127'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VS_CONFIG_SPEC = {\n",
    "    \"index_display_name\": DISPLAY_NAME,\n",
    "    \"contents_delta_uri\": CONTENTS_URI,\n",
    "    \"dimensions\": DIMENSIONS,\n",
    "    \"approximate_neighbors_count\": APPROX_NEIGHBORS,\n",
    "    \"distance_measure_type\": DISTANCE_MEASURE,\n",
    "    \"leaf_node_embedding_count\": LEAF_NODE_EMB_COUNT,\n",
    "    \"leaf_nodes_to_search_percent\": LEAF_SEARCH_PERCENT,\n",
    "    \"index_shard_size\": INDEX_SHARD_SIZE,\n",
    "    \"index_update_method\": INDEX_UPDATE_METHOD,\n",
    "    \"description\": DESCRIPTION,\n",
    "    \"labels\": {\n",
    "        \"prefix\": PREFIX\n",
    "    },\n",
    "    \"index_endpoint_display_name\": ENDPOINT_DISPLAY_NAME,\n",
    "    \"index_endpoint_description\": ENDPOINT_DESCRIPTION,\n",
    "    \"deployed_index_id\": DEPLOYED_INDEX_ID,\n",
    "}\n",
    "VS_CONFIG_SPEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3b103cd5-cc72-42ab-8841-6b755692aaca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TREE_AH_CONFIG = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"leafNodeEmbeddingCount\": struct_pb2.Value(\n",
    "            number_value=VS_CONFIG_SPEC[\"leaf_node_embedding_count\"]\n",
    "        ),\n",
    "        \"leafNodesToSearchPercent\": struct_pb2.Value(\n",
    "            number_value=VS_CONFIG_SPEC[\n",
    "                \"leaf_nodes_to_search_percent\"\n",
    "            ]\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "ALGORITHM_CONFIG = struct_pb2.Struct(\n",
    "    fields={\"treeAhConfig\": struct_pb2.Value(struct_value=TREE_AH_CONFIG)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "874e9ce4-8d12-44c9-8aac-818137f84d37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ALGORITHM_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "778525f7-1430-4446-b6fb-51fb78e854b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VS_CONFIG = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"dimensions\": struct_pb2.Value(\n",
    "            number_value=VS_CONFIG_SPEC[\"dimensions\"]\n",
    "        ),\n",
    "        \"approximateNeighborsCount\": struct_pb2.Value(\n",
    "            number_value=VS_CONFIG_SPEC[\"approximate_neighbors_count\"]\n",
    "        ),\n",
    "        \"distanceMeasureType\": struct_pb2.Value(\n",
    "            string_value=VS_CONFIG_SPEC[\"distance_measure_type\"]\n",
    "        ),\n",
    "        \"algorithmConfig\": struct_pb2.Value(struct_value=ALGORITHM_CONFIG),\n",
    "        \"shardSize\": struct_pb2.Value(string_value=VS_CONFIG_SPEC[\"index_shard_size\"]),\n",
    "    }\n",
    ")\n",
    "VS_METADATA = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"config\": struct_pb2.Value(struct_value=VS_CONFIG),\n",
    "        \"contentsDeltaUri\": struct_pb2.Value(\n",
    "            string_value=VS_CONFIG_SPEC[\"contents_delta_uri\"]\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a8ff1866-7a84-4ae1-9a59-a7c7cf6c1076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VS_METADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "144777fe-df36-4c51-966a-b52f82956a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INDEX_REQUEST = {\n",
    "    \"display_name\": VS_CONFIG_SPEC[\"index_display_name\"],\n",
    "    \"description\": VS_CONFIG_SPEC[\"description\"],\n",
    "    \"metadata\": struct_pb2.Value(struct_value=VS_METADATA),\n",
    "    \"index_update_method\": VS_CONFIG_SPEC[\"index_update_method\"],\n",
    "}\n",
    "  \n",
    "PARENT = f\"projects/{project_config['project_id']}/locations/{project_config['region']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0e72bfca-9a40-43cb-9a96-ecee91f12177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INDEX_REQUEST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab84b082-f12b-4d27-a0a9-050daba7aa19",
   "metadata": {},
   "source": [
    "## Create index \n",
    "\n",
    "> see **Troubleshooting** section below if encountering errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c65d3b2e-180d-4a24-8894-ec0d631771fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDEX_RESOURCE_NAME : projects/934903580331/locations/us-central1/indexes/1081325705452584960\n",
      "INDEX_DISPLAY_NAME  : soverflow_vvs_vectorio_pubv3\n"
     ]
    }
   ],
   "source": [
    "if CREATE_NEW_VS_INDEX:\n",
    "    \n",
    "    print(f\"Creating new index: {VS_CONFIG_SPEC['index_display_name']} ...\")\n",
    "    start = time.time()\n",
    "    create_lro = index_client.create_index(parent=PARENT, index=INDEX_REQUEST)\n",
    "    \n",
    "    # Poll the operation until it's done successfullly.\n",
    "    while True:\n",
    "        if create_lro.done():\n",
    "            break\n",
    "        time.sleep(5)\n",
    "        \n",
    "    index = create_lro.result()\n",
    "    my_vs_index = aiplatform.MatchingEngineIndex(index.name)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f\"elapsed time: {round((end - start), 2)}\")\n",
    "    \n",
    "else:\n",
    "    my_vs_index = aiplatform.MatchingEngineIndex(EXISTING_INDEX_NAME)\n",
    "    \n",
    "INDEX_RESOURCE_NAME = my_vs_index.resource_name\n",
    "INDEX_DISPLAY_NAME  = my_vs_index.display_name\n",
    "\n",
    "print(f\"INDEX_RESOURCE_NAME : {INDEX_RESOURCE_NAME}\")\n",
    "print(f\"INDEX_DISPLAY_NAME  : {INDEX_DISPLAY_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9bcf5b9-ac7b-4d97-9116-2d8ad55215db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/934903580331/locations/us-central1/indexes/1081325705452584960',\n",
       " 'displayName': 'soverflow_vvs_vectorio_pubv3',\n",
       " 'description': 'sample index for vectorio demo',\n",
       " 'metadataSchemaUri': 'gs://google-cloud-aiplatform/schema/matchingengine/metadata/nearest_neighbor_search_1.0.0.yaml',\n",
       " 'metadata': {'config': {'dimensions': 768.0,\n",
       "   'approximateNeighborsCount': 150.0,\n",
       "   'distanceMeasureType': 'DOT_PRODUCT_DISTANCE',\n",
       "   'algorithmConfig': {'treeAhConfig': {'leafNodeEmbeddingCount': '500',\n",
       "     'leafNodesToSearchPercent': 80.0}},\n",
       "   'shardSize': 'SHARD_SIZE_MEDIUM'}},\n",
       " 'deployedIndexes': [{'indexEndpoint': 'projects/934903580331/locations/us-central1/indexEndpoints/5739455095037231104',\n",
       "   'deployedIndexId': 'soverflow_vvs_vectorio_pubv3_20240130131739'}],\n",
       " 'etag': 'AMEw9yMreqkZWIbaAt6IqdpJ2c_z8XOT30Cwd7HFJHIFPz1FpFGVFgv_0PLQUNHKYfs=',\n",
       " 'createTime': '2024-01-30T13:26:08.725251Z',\n",
       " 'updateTime': '2024-01-30T13:26:17.176312Z',\n",
       " 'indexStats': {'vectorsCount': '1', 'shardsCount': 1},\n",
       " 'indexUpdateMethod': 'STREAM_UPDATE',\n",
       " 'encryptionSpec': {}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all index config to dictionary \n",
    "my_vs_index.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd40f2e-abc5-46b4-bfdc-d2bc8998d960",
   "metadata": {},
   "source": [
    "## Deploy index to endpoint\n",
    "\n",
    "*To list current index endpoints:*\n",
    "```\n",
    "!gcloud ai index-endpoints list --project=$PROJECT_ID --region=$REGION\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aa4f6d-9a60-4d20-b431-6ec97e87be53",
   "metadata": {},
   "source": [
    "### Create index endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bc1a2bfa-73cc-48a8-ae44-43752d800c5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXISTING_ENDPOINT_NAME  : projects/934903580331/locations/us-central1/indexEndpoints/5739455095037231104\n"
     ]
    }
   ],
   "source": [
    "CREATE_NEW_VS_INDEX_ENDPOINT = False\n",
    "\n",
    "# if using exsiting index endpoint\n",
    "if not CREATE_NEW_VS_INDEX_ENDPOINT:\n",
    "    EXISTING_ENDPOINT_ID = \"5739455095037231104\" # TODO\n",
    "    EXISTING_ENDPOINT_NAME = f'projects/{PROJECT_NUM}/locations/{REGION}/indexEndpoints/{EXISTING_ENDPOINT_ID}'\n",
    "    print(f\"EXISTING_ENDPOINT_NAME  : {EXISTING_ENDPOINT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c8c2756-5db9-4448-a5c1-77ed85f493d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENDPOINT_DISPLAY_NAME  : soverflow_vvs_vectorio_pubv3_endpoint\n",
      "ENDPOINT_RESOURCE_NAME : projects/934903580331/locations/us-central1/indexEndpoints/5739455095037231104\n"
     ]
    }
   ],
   "source": [
    "if CREATE_NEW_VS_INDEX_ENDPOINT:\n",
    "    \n",
    "    print(f\"Creating new index endpoint: {VS_CONFIG_SPEC['index_endpoint_display_name']} ...\")\n",
    "    start = time.time()\n",
    "    my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "        display_name=VS_CONFIG_SPEC[\"index_endpoint_display_name\"],\n",
    "        description=VS_CONFIG_SPEC[\"index_endpoint_description\"],\n",
    "        network=VPC_NETWORK_FULL if not USE_PUBLIC_ENDPOINTS else None,\n",
    "        public_endpoint_enabled=USE_PUBLIC_ENDPOINTS,\n",
    "        sync=True,\n",
    "    )\n",
    "    end = time.time()\n",
    "    print(f\"elapsed time: {round((end - start), 2)}\")\n",
    "    \n",
    "else:\n",
    "    my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(EXISTING_ENDPOINT_NAME)\n",
    "    \n",
    "ENDPOINT_DISPLAY_NAME  = my_index_endpoint.display_name\n",
    "ENDPOINT_RESOURCE_NAME = my_index_endpoint.resource_name\n",
    "\n",
    "print(f\"ENDPOINT_DISPLAY_NAME  : {ENDPOINT_DISPLAY_NAME}\")\n",
    "print(f\"ENDPOINT_RESOURCE_NAME : {ENDPOINT_RESOURCE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a61d40a-06c5-4361-b9f6-9b35d092b4a3",
   "metadata": {},
   "source": [
    "### Deploy to index endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b80c0d43-5e6e-4e5f-bf4e-a95a00e8b997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEPLOY_NEW_VS_INDEX = False\n",
    "\n",
    "# # if using exsiting deployed index\n",
    "# if not DEPLOY_NEW_VS_INDEX:\n",
    "#     EXISTING_DEPLOYED_INDEX_ID = \"...\" # TODO\n",
    "#     EXISTING_DEPLOYED_INDEX_NAME = f'projects/{PROJECT_NUM}/locations/{REGION}/indexEndpoints/{EXISTING_DEPLOYED_INDEX_ID}'\n",
    "#     print(f\"EXISTING_DEPLOYED_INDEX_NAME  : {EXISTING_DEPLOYED_INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a5bd3f5f-7078-474d-b707-095eb4ebf871",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUBLIC_ENDPOINT_URL    : 139422526.us-central1-934903580331.vdb.vertexai.goog\n",
      "DEPLOYED_INDEX_ID_TEST : soverflow_vvs_vectorio_pubv3_20240130131739\n"
     ]
    }
   ],
   "source": [
    "if DEPLOY_NEW_VS_INDEX:\n",
    "    \n",
    "    print(f\"Deploying index to endpoint: {ENDPOINT_DISPLAY_NAME} ...\")\n",
    "    start = time.time()\n",
    "\n",
    "    deployed_index = my_index_endpoint.deploy_index(\n",
    "        index=my_vs_index,\n",
    "        deployed_index_id=VS_CONFIG_SPEC['deployed_index_id'],\n",
    "        min_replica_count=MIN_REPLICAS,\n",
    "        max_replica_count=MAX_REPLICAS,\n",
    "    )\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f\"elapsed time: {round((end - start), 2)}\")\n",
    "else:\n",
    "    deployed_index = aiplatform.MatchingEngineIndexEndpoint(EXISTING_ENDPOINT_NAME)\n",
    "    \n",
    "PUBLIC_ENDPOINT_URL = deployed_index.public_endpoint_domain_name\n",
    "DEPLOYED_INDEX_ID_TEST = deployed_index.deployed_indexes[0].id\n",
    "\n",
    "print(f\"PUBLIC_ENDPOINT_URL    : {PUBLIC_ENDPOINT_URL}\")\n",
    "print(f\"DEPLOYED_INDEX_ID_TEST : {DEPLOYED_INDEX_ID_TEST}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fcc694e1-ff2d-4d5c-9800-15781ea826bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployed indexes on the index endpoint:\n",
      "    soverflow_vvs_vectorio_pubv3_20240130131739\n"
     ]
    }
   ],
   "source": [
    "print(f\"Deployed indexes on the index endpoint:\")\n",
    "for d in my_index_endpoint.deployed_indexes:\n",
    "    print(f\"    {d.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca81cb04-782d-4be7-89e5-229dc2654eab",
   "metadata": {},
   "source": [
    "### Get Index and Endpoint IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "99cabb39-009e-4c49-9251-b064397a365c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MY_INDEX_ID          = 1081325705452584960\n",
      "MY_INDEX_ENDPOINT_ID = 5739455095037231104\n"
     ]
    }
   ],
   "source": [
    "MY_INDEX_ID          = INDEX_RESOURCE_NAME.split(\"/\")[5]\n",
    "MY_INDEX_ENDPOINT_ID = ENDPOINT_RESOURCE_NAME.split(\"/\")[5]\n",
    "\n",
    "print(f\"MY_INDEX_ID          = {MY_INDEX_ID}\")\n",
    "print(f\"MY_INDEX_ENDPOINT_ID = {MY_INDEX_ENDPOINT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7c9224-061a-4dcb-b8a2-891954b7708d",
   "metadata": {},
   "source": [
    "## Check vector count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e0f654b-9322-4afa-a33e-806a45dfdd67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 1\n"
     ]
    }
   ],
   "source": [
    "number_of_vectors = sum(\n",
    "    aiplatform.MatchingEngineIndex(\n",
    "        deployed_index.index\n",
    "    )._gca_resource.index_stats.vectors_count\n",
    "    for deployed_index in my_index_endpoint.deployed_indexes\n",
    ")\n",
    "\n",
    "print(f\"Actual: {number_of_vectors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46347905-da51-4c29-af68-96089a71c089",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save notebook config \n",
    "\n",
    "> to easily use in other GCP related notebooks\n",
    "\n",
    "**TODO**\n",
    "* add more variables to be re-used in import class test\n",
    "* add more variables to be re-used in export class test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ccf897d7-a19b-4ec7-9fba-5fda7129bf4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/stack_overflow_parquet_pubv3/files/so_tmpm4k5k6gq_2001.parquet|data/stack_overflow_parquet_pubv3/files/so_tmpm4k5k6gq_2000.parquet|data/stack_overflow_parquet_pubv3/files/so_tmpm4k5k6gq_2002.parquet'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOCAL_PARQUEST_FILE_STR = '|'.join(LOCAL_PARQUEST_FILE_LIST)\n",
    "LOCAL_PARQUEST_FILE_STR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "334631cf-dac5-4d3f-a0ce-fc30aa2fc614",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PREFIX                   = \"vvs-vectorio-pubv3\"\n",
      "VERSION                  = \"pubv3\"\n",
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_REGION                = \"US\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "VPC_NETWORK_NAME         = \"\"\n",
      "VPC_NETWORK_FULL         = \"None\"\n",
      "\n",
      "USE_PUBLIC_ENDPOINTS     = \"True\"\n",
      "\n",
      "BUCKET_NAME              = \"vvs-vectorio-pubv3-hybrid-vertex\"\n",
      "BUCKET_URI               = \"gs://vvs-vectorio-pubv3-hybrid-vertex\"\n",
      "\n",
      "REMOTE_GCS_FOLDER        = \"gs://vvs-vectorio-pubv3-hybrid-vertex/vvs-vectorio-pubv3/embedding_indexes/tmpm4k5k6gq/\"\n",
      "\n",
      "SO_PARQUET_GCS_DIR       = \"gs://vvs-vectorio-pubv3-hybrid-vertex/emb_vector_parquet/so_2000_5000_1000/tmpsgm4txp8/\"\n",
      "\n",
      "LOCAL_TEST_DIR           = \"data/stack_overflow_parquet_pubv3\"\n",
      "LOCAL_TEST_DATA_DIR      = \"data/stack_overflow_parquet_pubv3/files\"\n",
      "\n",
      "DIMENSIONS               = \"768\"\n",
      "\n",
      "INDEX_DISPLAY_NAME       = \"soverflow_vvs_vectorio_pubv3\"\n",
      "INDEX_RESOURCE_NAME      = \"projects/934903580331/locations/us-central1/indexes/1081325705452584960\"\n",
      "MY_INDEX_ID              = \"1081325705452584960\"\n",
      "\n",
      "ENDPOINT_DISPLAY_NAME    = \"soverflow_vvs_vectorio_pubv3_endpoint\"\n",
      "ENDPOINT_RESOURCE_NAME   = \"projects/934903580331/locations/us-central1/indexEndpoints/5739455095037231104\"\n",
      "MY_INDEX_ENDPOINT_ID     = \"5739455095037231104\"\n",
      "\n",
      "DEPLOYED_INDEX_ID        = \"soverflow_vvs_vectorio_pubv3_20240130131739\"\n",
      "\n",
      "PUBLIC_ENDPOINT_URL      = \"139422526.us-central1-934903580331.vdb.vertexai.goog\"\n",
      "\n",
      "LOCAL_PARQUEST_FILE_LIST = \"data/stack_overflow_parquet_pubv3/files/so_tmpm4k5k6gq_2001.parquet|data/stack_overflow_parquet_pubv3/files/so_tmpm4k5k6gq_2000.parquet|data/stack_overflow_parquet_pubv3/files/so_tmpm4k5k6gq_2002.parquet\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = f\"\"\"\n",
    "PREFIX                   = \\\"{PREFIX}\\\"\n",
    "VERSION                  = \\\"{VERSION}\\\"\n",
    "\n",
    "PROJECT_ID               = \\\"{PROJECT_ID}\\\"\n",
    "PROJECT_NUM              = \\\"{PROJECT_NUM}\\\"\n",
    "\n",
    "REGION                   = \\\"{REGION}\\\"\n",
    "BQ_REGION                = \\\"{BQ_REGION}\\\"\n",
    "\n",
    "VERTEX_SA                = \\\"{VERTEX_SA}\\\"\n",
    "\n",
    "VPC_NETWORK_NAME         = \\\"{VPC_NETWORK_NAME}\\\"\n",
    "VPC_NETWORK_FULL         = \\\"{VPC_NETWORK_FULL}\\\"\n",
    "\n",
    "USE_PUBLIC_ENDPOINTS     = \\\"{USE_PUBLIC_ENDPOINTS}\\\"\n",
    "\n",
    "BUCKET_NAME              = \\\"{BUCKET_NAME}\\\"\n",
    "BUCKET_URI               = \\\"{BUCKET_URI}\\\"\n",
    "\n",
    "REMOTE_GCS_FOLDER        = \\\"{REMOTE_GCS_FOLDER}\\\"\n",
    "\n",
    "SO_PARQUET_GCS_DIR       = \\\"{SO_PARQUET_GCS_DIR}\\\"\n",
    "\n",
    "LOCAL_TEST_DIR           = \\\"{LOCAL_TEST_DIR}\\\"\n",
    "LOCAL_TEST_DATA_DIR      = \\\"{LOCAL_TEST_DATA_DIR}\\\"\n",
    "\n",
    "DIMENSIONS               = \\\"{DIMENSIONS}\\\"\n",
    "\n",
    "INDEX_DISPLAY_NAME       = \\\"{INDEX_DISPLAY_NAME}\\\"\n",
    "INDEX_RESOURCE_NAME      = \\\"{INDEX_RESOURCE_NAME}\\\"\n",
    "MY_INDEX_ID              = \\\"{MY_INDEX_ID}\\\"\n",
    "\n",
    "ENDPOINT_DISPLAY_NAME    = \\\"{ENDPOINT_DISPLAY_NAME}\\\"\n",
    "ENDPOINT_RESOURCE_NAME   = \\\"{ENDPOINT_RESOURCE_NAME}\\\"\n",
    "MY_INDEX_ENDPOINT_ID     = \\\"{MY_INDEX_ENDPOINT_ID}\\\"\n",
    "\n",
    "DEPLOYED_INDEX_ID        = \\\"{DEPLOYED_INDEX_ID}\\\"\n",
    "\n",
    "PUBLIC_ENDPOINT_URL      = \\\"{PUBLIC_ENDPOINT_URL}\\\"\n",
    "\n",
    "LOCAL_PARQUEST_FILE_LIST = \\\"{LOCAL_PARQUEST_FILE_STR}\\\"\n",
    "\"\"\"\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6cf3a97a-8dbe-4bfd-9a38-8b313892a8d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying from <STDIN>...\n",
      "/ [1 files][    0.0 B/    0.0 B]                                                \n",
      "Operation completed over 1 objects.                                              \n"
     ]
    }
   ],
   "source": [
    "!echo '{config}' | gsutil cp - {BUCKET_URI}/config/notebook_env.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8216b733-fd53-4823-8084-5eb01e55f021",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a7eef8-c37e-404d-bf25-72df099b8f94",
   "metadata": {},
   "source": [
    "If index creation fails, grab `OPERATION_ID` and `FAILED_INDEX_ID` from the operation resource name in the error message, for example:\n",
    "\n",
    "> `Please check the details in the metadata of operation: projects/934903580331/locations/us-central1/indexes/FAILED_INDEX_ID/operations/OPERATION_ID.`\n",
    "\n",
    "Then, use `gcloud ai operations describe` to get the error details:\n",
    "\n",
    "```\n",
    "!gcloud ai operations describe $OPERATION_ID \\\n",
    "    --index=$FAILED_INDEX_ID \\\n",
    "    --project=$PROJECT_ID \\\n",
    "    --region=$REGION\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc6215-6a7e-473c-8d96-4891e74d8a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPERATION_ID    = \"2710742495469240320\"\n",
    "# FAILED_INDEX_ID = \"4846053518957608960\"\n",
    "\n",
    "# !gcloud ai operations describe $OPERATION_ID \\\n",
    "#     --index=$FAILED_INDEX_ID \\\n",
    "#     --project=$PROJECT_ID \\\n",
    "#     --region=$REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5384cdd1-6048-4c3f-b4e2-9fdee3b70c29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Clean-up\n",
    "\n",
    "> TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f784625-4d56-4a25-8cdd-064bf99e8807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# delete_bucket = False\n",
    "\n",
    "# # Force undeployment of indexes and delete endpoint\n",
    "# my_index_endpoint.delete(force=True)\n",
    "\n",
    "# # Delete indexes\n",
    "# tree_ah_index.delete()\n",
    "\n",
    "# if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "#     ! gsutil rm -rf {BUCKET_URI}"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m115"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
