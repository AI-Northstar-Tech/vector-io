{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhruvanand/miniforge3/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /Users/dhruvanand/miniforge3/lib/python3.10/site-packages (10.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from transformers import ResNetModel, ConvNextImageProcessor\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "model = ResNetModel.from_pretrained(\"microsoft/resnet-50\")\n",
    "# embed https://upload.wikimedia.org/wikipedia/commons/8/8b/Scolopendra_gigantea.jpg\n",
    "image_url = \"/Users/dhruvanand/Code/vector-io/Scolopendra_gigantea.jpg\"\n",
    "\n",
    "\n",
    "# Load the image as a torch tensor\n",
    "\n",
    "image_processor = ConvNextImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "model = ResNetModel.from_pretrained(\"microsoft/resnet-50\")\n",
    "img = Image.open(image_url)\n",
    "inputs = image_processor(images=img, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "print(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2048])\n"
     ]
    }
   ],
   "source": [
    "# apply GMP over the outputs.hidden_states[-1] which is of shape (1, 2048, 7, 7)\n",
    "# to get a single vector of shape (1, 2048)\n",
    "pooled_output = outputs.last_hidden_state.max(dim=2).values.max(dim=2).values\n",
    "\n",
    "print(pooled_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0637, 2.6114, 0.0000,  ..., 0.1222, 1.0969, 0.0000]],\n",
       "       grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flax\n",
      "  Obtaining dependency information for flax from https://files.pythonhosted.org/packages/8d/4a/7e78abc8392ff21b0257deb79e842f80647b63b745447df94893732d60fd/flax-0.8.1-py3-none-any.whl.metadata\n",
      "  Downloading flax-0.8.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.22 in /Users/dhruvanand/miniforge3/lib/python3.10/site-packages (from flax) (1.26.3)\n",
      "Collecting jax>=0.4.19 (from flax)\n",
      "  Obtaining dependency information for jax>=0.4.19 from https://files.pythonhosted.org/packages/35/c1/51a51ea646864ef8b4bd68632162ed1b4495c580b9bfa72fe49168221d69/jax-0.4.24-py3-none-any.whl.metadata\n",
      "  Downloading jax-0.4.24-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting msgpack (from flax)\n",
      "  Obtaining dependency information for msgpack from https://files.pythonhosted.org/packages/ad/72/d39ed43bfb2ec6968d768318477adb90c474bdc59b2437170c6697ee4115/msgpack-1.0.7-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading msgpack-1.0.7-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting optax (from flax)\n",
      "  Obtaining dependency information for optax from https://files.pythonhosted.org/packages/bb/c6/ca58ae4ed7283c65ab53318096cd53a3ab78462d0488a185eef3cf2f2d04/optax-0.1.9-py3-none-any.whl.metadata\n",
      "  Downloading optax-0.1.9-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting orbax-checkpoint (from flax)\n",
      "  Obtaining dependency information for orbax-checkpoint from https://files.pythonhosted.org/packages/83/a2/0677f2ee06bdbf7b4e6be4ad931ffe58f2ea82d67bb2a277d9d7b3b1e352/orbax_checkpoint-0.5.3-py3-none-any.whl.metadata\n",
      "  Downloading orbax_checkpoint-0.5.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorstore (from flax)\n",
      "  Obtaining dependency information for tensorstore from https://files.pythonhosted.org/packages/15/c9/c93f3833acda1074fb261bea8d3c7a6955e979a6a1512913c11f4e9d3414/tensorstore-0.1.53-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading tensorstore-0.1.53-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: rich>=11.1 in /Users/dhruvanand/miniforge3/lib/python3.10/site-packages (from flax) (13.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /Users/dhruvanand/miniforge3/lib/python3.10/site-packages (from flax) (4.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /Users/dhruvanand/miniforge3/lib/python3.10/site-packages (from flax) (6.0.1)\n",
      "Collecting ml-dtypes>=0.2.0 (from jax>=0.4.19->flax)\n",
      "  Obtaining dependency information for ml-dtypes>=0.2.0 from https://files.pythonhosted.org/packages/62/0a/2b586fd10be7b8311068f4078623a73376fc49c8b3768be9965034062982/ml_dtypes-0.3.2-cp310-cp310-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading ml_dtypes-0.3.2-cp310-cp310-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum (from jax>=0.4.19->flax)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.9 in /Users/dhruvanand/miniforge3/lib/python3.10/site-packages (from jax>=0.4.19->flax) (1.11.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/dhruvanand/miniforge3/lib/python3.10/site-packages (from rich>=11.1->flax) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/dhruvanand/miniforge3/lib/python3.10/site-packages (from rich>=11.1->flax) (2.17.2)\n",
      "Collecting absl-py>=0.7.1 (from optax->flax)\n",
      "  Obtaining dependency information for absl-py>=0.7.1 from https://files.pythonhosted.org/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl.metadata\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting chex>=0.1.7 (from optax->flax)\n",
      "  Obtaining dependency information for chex>=0.1.7 from https://files.pythonhosted.org/packages/9a/82/257141baabfaf8b0187521ddb83e996f2a71cdd4f7796d9599ca3e3ea4a9/chex-0.1.85-py3-none-any.whl.metadata\n",
      "  Downloading chex-0.1.85-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting jaxlib>=0.1.37 (from optax->flax)\n",
      "  Obtaining dependency information for jaxlib>=0.1.37 from https://files.pythonhosted.org/packages/ec/ee/0aa26c9094ec7962bdeb6818b25d5a356864cdc5081b93d62e5ebba6e144/jaxlib-0.4.24-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading jaxlib-0.4.24-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting etils[epath,epy] (from orbax-checkpoint->flax)\n",
      "  Obtaining dependency information for etils[epath,epy] from https://files.pythonhosted.org/packages/37/10/dd5b124f037a636783e416a2fe839edd7ec63c0dce7ce4f3c1da029aeb80/etils-1.7.0-py3-none-any.whl.metadata\n",
      "  Downloading etils-1.7.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: nest_asyncio in /Users/dhruvanand/miniforge3/lib/python3.10/site-packages (from orbax-checkpoint->flax) (1.5.8)\n",
      "Requirement already satisfied: protobuf in /Users/dhruvanand/miniforge3/lib/python3.10/site-packages (from orbax-checkpoint->flax) (4.25.1)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /Users/dhruvanand/miniforge3/lib/python3.10/site-packages (from chex>=0.1.7->optax->flax) (0.12.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/dhruvanand/miniforge3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/dhruvanand/miniforge3/lib/python3.10/site-packages (from etils[epath,epy]->orbax-checkpoint->flax) (2023.10.0)\n",
      "Collecting importlib_resources (from etils[epath,epy]->orbax-checkpoint->flax)\n",
      "  Obtaining dependency information for importlib_resources from https://files.pythonhosted.org/packages/93/e8/facde510585869b5ec694e8e0363ffe4eba067cb357a8398a55f6a1f8023/importlib_resources-6.1.1-py3-none-any.whl.metadata\n",
      "  Downloading importlib_resources-6.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: zipp in /Users/dhruvanand/miniforge3/lib/python3.10/site-packages (from etils[epath,epy]->orbax-checkpoint->flax) (3.17.0)\n",
      "Downloading flax-0.8.1-py3-none-any.whl (677 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.6/677.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jax-0.4.24-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading msgpack-1.0.7-cp310-cp310-macosx_11_0_arm64.whl (231 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.0/232.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading optax-0.1.9-py3-none-any.whl (197 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.2/197.2 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orbax_checkpoint-0.5.3-py3-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorstore-0.1.53-cp310-cp310-macosx_11_0_arm64.whl (12.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chex-0.1.85-py3-none-any.whl (95 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.1/95.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jaxlib-0.4.24-cp310-cp310-macosx_11_0_arm64.whl (68.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-macosx_10_9_universal2.whl (389 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.8/389.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading etils-1.7.0-py3-none-any.whl (152 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: opt-einsum, msgpack, ml-dtypes, importlib_resources, etils, absl-py, tensorstore, jaxlib, jax, chex, orbax-checkpoint, optax, flax\n",
      "Successfully installed absl-py-2.1.0 chex-0.1.85 etils-1.7.0 flax-0.8.1 importlib_resources-6.1.1 jax-0.4.24 jaxlib-0.4.24 ml-dtypes-0.3.2 msgpack-1.0.7 opt-einsum-3.3.0 optax-0.1.9 orbax-checkpoint-0.5.3 tensorstore-0.1.53\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhruvanand/miniforge3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/dhruvanand/miniforge3/lib/python3.10/site-packages/transformers/models/convnext/feature_extraction_convnext.py:28: FutureWarning: The class ConvNextFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ConvNextImageProcessor instead.\n",
      "  warnings.warn(\n",
      "flax_model.msgpack: 100%|██████████| 102M/102M [00:06<00:00, 15.1MB/s] \n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from transformers import ConvNextFeatureExtractor, FlaxResNetModel\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "image_processor = ConvNextFeatureExtractor.from_pretrained(\"microsoft/resnet-50\")\n",
    "model = FlaxResNetModel.from_pretrained(\"microsoft/resnet-50\")\n",
    "inputs = image_processor(images=image, return_tensors=\"np\")\n",
    "outputs = model(**inputs)\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2048, 7, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      4\u001b[0m gap \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mAdaptiveAvgPool2d((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m----> 5\u001b[0m x_reduced \u001b[38;5;241m=\u001b[39m \u001b[43mgap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_hidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Remove extra dimensions to get a (1, 2048) vector\u001b[39;00m\n\u001b[1;32m      8\u001b[0m x_reduced \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x_reduced, start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/pooling.py:1194\u001b[0m, in \u001b[0;36mAdaptiveAvgPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madaptive_avg_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/functional.py:1227\u001b[0m, in \u001b[0;36madaptive_avg_pool2d\u001b[0;34m(input, output_size)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m   1226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(adaptive_avg_pool2d, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, output_size)\n\u001b[0;32m-> 1227\u001b[0m _output_size \u001b[38;5;241m=\u001b[39m _list_with_default(output_size, \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39madaptive_avg_pool2d(\u001b[38;5;28minput\u001b[39m, _output_size)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "x_reduced = gap(last_hidden_states)\n",
    "\n",
    "# Remove extra dimensions to get a (1, 2048) vector\n",
    "x_reduced = torch.flatten(x_reduced, start_dim=1)\n",
    "\n",
    "print(x_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
